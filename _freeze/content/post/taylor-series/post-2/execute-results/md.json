{
  "hash": "b297a75c737f747ed5980cdd12d3fe47",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Making a Python Library to solve differential Equations\"\nauthor: 'Alfie Chadwick'\ndate: '2023-12-29'\nlastmod: \"`r Sys.Date()`\"\nTags: ['Calculus', 'Algebra','Python']\n---\n\n\n\n\nAfter having the initial idea I wrote up in a [previous post](/2023/12/18/using-taylor-series-to-improve-the-euler-method/), I thought it was a good idea to turn it into a python library so that I can use it as part of my other projects.\n\nIt also gives me a chance to see numerically how well the new method works compared to the Euler method.\n\n# First Steps\n\nSo in the last post I set out the method such that:\n$$ \\begin{bmatrix}\ny(x+h)\\\\\ny'(x+h)\\\\\ny''(x+h)\\\\\n...\\\\\ny^{n}(x+h)\\\\\n\\end{bmatrix} =  S \\cdot \\begin{bmatrix}\ny(x)\\\\\ny'(x)\\\\\ny''(x)\\\\\n...\\\\\ny^{n}(x)\\\\\n\\end{bmatrix} + \\epsilon $$ \n\nIn the Euler method, $S$ is:\n$$\\begin{bmatrix}\n1 & h & 0 &  ... & 0\\\\\n0 & 1 & h &  ... & 0\\\\\n0 & 0 & 1 &  ... & 0\\\\\n... & ... & ... &  ... & ...\\\\\n0 & 0 & 0 &  ... & 1\\\\\n\\end{bmatrix}$$\n\nAnd in the new method I proposed, $S$ is now:\n$$ \\begin{bmatrix}\n1 & \\frac{h}{1!} & \\frac{h^2}{2!} &  ... & \\frac{h^n}{n!}\\\\\n0 & 1 & \\frac{h}{1!} &  ... & \\frac{h^{n-1}}{(n-1)!}\\\\\n0 & 0 & 1 &  ... & \\frac{h^{n-2}}{(n-2)!}\\\\\n... & ... & ... &  ... & ...\\\\\n0 & 0 & 0 &  ... & 1\\\\\n\\end{bmatrix}$$\n\nConverting these matrices into python is fairly easy.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport math\n\n\ndef euler(dims, h):\n    # Start with an identity matrix\n    step_matrix = np.identity(dims)\n    # Add in all the h values\n    for i in range(dims - 1):\n        step_matrix[i, i + 1] = h\n    return step_matrix\n\n\ndef expanded_euler(dims, h):\n    step_matrix = np.zeros((dims, dims))\n    for i in range(dims):\n        for j in range(i, dims):\n            # Is 1, and h at j-i =0, 1 respectively\n            step_matrix[i, j] = h ** (j - i) / math.factorial(j - i)\n    return step_matrix\n```\n:::\n\n\n# Making a step simulation\n\nNow that we have the stepping matrices, we can use them to iterate from an initial value. All we have to do is generate the stepping matrix for the given problem, and then for each step, we just multiple the previous step by the stepping matrix.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef IVP(x, y, step_matrix_generator, steps=10, h=0.1):\n    dims = len(y)\n    step_matrix = step_matrix_generator(dims, h)\n    output_dict = {x: y}\n\n    x_n = x\n    y_n = y.copy()\n    i = 0\n    while i < steps:\n        y_n = step_matrix @ y_n\n        x_n += h\n        output_dict[x_n] = y_n\n        i += 1\n\n    return output_dict\n```\n:::\n\n\n# Testing and Comparing the methods\n\n\nNow we can run the simulations, let's see how good they are.\nSay you throw a ball up in the air and track its vertical position. The path of the ball is described by the equation $y'' = -9.8$. We can know for a fact that the solution to this equation is $\\frac{-9.8}{2}x^2+V_0x+P_0$, where $V_0$ is the initial velocity and $P_0$ is the initial position. So now lets compare the real solutions to the simulations.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Time starts at 0\nx = 0\n# Start the object moving upwards with a velocity of 10\ny = np.array([0, 10, -9.8])\n\neuler_result = IVP(x, y, euler)\nexpanded_euler_result =IVP(x, y, expanded_euler)\ntrue_result = {x: np.array([\n                    -4.9 * x**2 + 10 * x,\n                    -9.8 * x + 10,\n                    -9.8\n                ]) for x in np.arange(0, 1.1, 0.1)}\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport mplcatppuccin\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.style.use(\"macchiato\")\n\n# Extracting data for plotting\neuler_xs = list(euler_result.keys())\neuler_ys = [position[0] for position in euler_result.values()]\n\nexpanded_euler_xs = list(expanded_euler_result.keys())\nexpanded_euler_ys = [position[0] for position in expanded_euler_result.values()]\n\ntrue_xs = list(true_result.keys())\ntrue_ys = [position[0] for position in true_result.values()]\n\n# Plotting the results\nplt.plot(euler_xs, euler_ys, label='Euler Method')\nplt.plot(expanded_euler_xs, expanded_euler_ys, label='Expanded Euler Method')\nplt.plot(true_xs, true_ys, label='True Solution', linestyle=':')\n\nplt.title('Projectile Motion under Gravity')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Height (meters)')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post-2_files/figure-markdown_strict/cell-5-output-1.png){width=651 height=449}\n:::\n:::\n\n\nSo from here, we're looking pretty good. The new method is much closer to the true solution than the Euler method in in this scenario. However, when working with numerical methods, it generally isn't too hard to improve the accuracy of the model, but there will be a trade off in computation time. So lets see how much longer it takes to compute the approximation with the expanded method comparing it to the original.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport timeit\n\n# Define the step counts to test\nsteps_list = [10, 100, 1000, 10000, 100000]\n\n# Lists to store execution times for each method\neuler_times = []\nexpanded_euler_times = []\n\n# Testing the functions with the different step counts and store the execution times\nfor steps in steps_list:\n    euler_time = timeit.timeit(lambda: IVP(x, y, euler, steps), number=1)\n    expanded_euler_time = timeit.timeit(lambda: IVP(x, y, expanded_euler, steps), number=1)\n    \n    euler_times.append(euler_time)\n    expanded_euler_times.append(expanded_euler_time)\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Now we plot the results\nplt.figure(figsize=(10, 5))\n\n# Plot Euler times\nplt.plot(steps_list, euler_times, label='Euler Method', marker='o')\n\n# Plot Expanded Euler times\nplt.plot(steps_list, expanded_euler_times, label='Expanded Euler Method', marker='s')\n\n# Adding labels and title\nplt.xlabel('Number of Steps')\nplt.ylabel('Execution Time (seconds)')\nplt.title('Execution Time for Euler Methods with Different Steps')\nplt.xscale('log')  # Since we have a wide range of steps, a log scale might be more informative\nplt.yscale('log')  # Using a log scale for time to better see differences for small times\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post-2_files/figure-markdown_strict/cell-7-output-1.png){width=822 height=451}\n:::\n:::\n\n\nLooking at this graph, we can see that we're not sacrificing compute time for better accuracy, so this seems like a big win, though I haven't optimised the Euler method that much. But overall, the new method seems to show some promise in approximating differential equations.\n\n",
    "supporting": [
      "post-2_files"
    ],
    "filters": [],
    "includes": {}
  }
}
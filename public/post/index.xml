<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Alfie Chadwick</title>
        <link>/post/</link>
        <description>Recent content in Posts on Alfie Chadwick</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 03 Feb 2024 00:00:00 +0000</lastBuildDate>
        <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>A Follow Up on my Hottest 100 Predictions</title>
            <link>/2024/02/03/a-follow-up-on-my-hottest-100-predictions/</link>
            <pubDate>Sat, 03 Feb 2024 00:00:00 +0000</pubDate>
            
            <guid>/2024/02/03/a-follow-up-on-my-hottest-100-predictions/</guid>
            <description>In my last post I ended by planting my flag and making my predictions for the Hottest 100 for 2023. And on first glance, I’m pretty happy with myself, picking not only the top song, but a good chunk of the top 20. So today I just want to do a quick follow up on how I did.
Top 20 ## Song Artist Predicted ## 1 paint the town red doja cat 1 ## 2 the worst person alive g flip 55 ## 3 saving up dom dolla NA ## 4 rhyme dust mk 72 ## 5 prada cass 90 ## 6 adore u fred again 40 ## 7 what was i made for?</description>
            <content type="html"><![CDATA[


<p>In my <a href="/2024/01/26/predicting-the-2023-hottest-100/">last post</a> I ended by planting my flag and making my predictions for the Hottest 100 for 2023. And on first glance, I’m pretty happy with myself, picking not only the top song, but a good chunk of the top 20. So today I just want to do a quick follow up on how I did.</p>
<div id="top-20" class="section level1">
<h1>Top 20</h1>
<pre><code>##                      Song         Artist Predicted
## 1      paint the town red       doja cat         1
## 2  the worst person alive         g flip        55
## 3               saving up      dom dolla        NA
## 4              rhyme dust             mk        72
## 5                   prada           cass        90
## 6                 adore u     fred again        40
## 7    what was i made for?  billie eilish         3
## 8                    rush    troye sivan        10
## 9             lovin on me    jack harlow        17
## 10               chemical    post malone        14
## 11                vampire olivia rodrigo         2
## 12                 rumble       skrillex        NA
## 13              kill bill            sza         9
## 14             atmosphere         fisher        NA
## 15                 nanana      peggy gou         5
## 16               sprinter           dave         4
## 17             back on 74         jungle        NA
## 18           eat your man      dom dolla        NA
## 19                therapy       budjerah        NA
## 20          sorry instead    spacey jane        NA</code></pre>
<p>The top 10 seems okay, but i did miss a lot of the top 20 completely. I seemed to be undervaluing Australian artists such as Dom Dolla, Spacey Jane, and G Flip, as well as EDM as a genre, which made up a much greater portion of the top 20 than I predicted.</p>
</div>
<div id="snubbed-songs" class="section level1">
<h1>Snubbed Songs</h1>
<pre><code>##                       Song                Artist Predicted
## 1                love type              poolclvb         6
## 2                super ego          babe rainbow         8
## 3                   adored            royel otis        15
## 4         lost without you             san cisco        21
## 5             super-vision                  dice        22
## 6             blak britney          miss kaninna        24
## 7                 ruthless         hooligan hefs        26
## 8                attention              doja cat        27
## 9               james dean          tash sultana        28
## 10             do it again                 benee        33
## 11        i wish you roses            kali uchis        35
## 12           dash of speed            rum jungle        36
## 13                too much         the kid laroi        37
## 14              eyes ahead                  dice        38
## 15          pets and drugs            the rubens        42
## 16          into your room     holly humberstone        44
## 17                      up                   lee        46
## 18                 pegasus            arlo parks        47
## 19               exploding         angie mcmahon        48
## 20                 calling          metro boomin        50
## 21            must be nice                  ruel        51
## 22             better love            eliza rose        52
## 23            your funeral                  maya        53
## 24       don&#39;t let me down         gus dapperton        54
## 25               conceited            lola young        56
## 26               messed up             holy holy        57
## 27        lost in the rush              telenova        58
## 28            candle flame                jungle        59
## 29            prescription             remi wolf        63
## 30                  change                laurel        64
## 31                   angel        pinkpantheress        65
## 32                  sinner the last dinner party        66
## 33                 midwest             vacations        67
## 34             pretty girl             ice spice        68
## 35           i wanna dance            royel otis        71
## 36       make up your mind                cordae        74
## 37              viper room             thornhill        75
## 38              weightless            arlo parks        76
## 39       can&#39;t play myself                skepta        78
## 40          black mascara.                  raye        79
## 41              feel alive                   cat        80
## 42                tied up!         genesis owusu        81
## 43          mrs. hollywood                  gojo        84
## 44           am i dreaming          metro boomin        85
## 45                 comma&#39;s               onefour        86
## 46                    lola                  maya        87
## 47 it&#39;s cool to be in love         greta stanley        88
## 48    since i have a lover                 6lack        89
## 49           lil boo thang          paul russell        91
## 50            going kokomo            royel otis        93
## 51             all my life              lil durk        94
## 52            brain freeze northeast party house        95
## 53                 healing      molly millington        96
## 54                  sticky                  kito        97
## 55                  rakata     the jungle giants        98</code></pre>
<p>So there were 55 songs in my predictions that didn’t make it into the countdown, including 3 of my top 20. Funily enough though, a lot of my predictions seemed to line up with peoples opions online with <a href="https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1b24c/?utm_source=share&amp;utm_medium=web2x&amp;context=3">Love Type</a>, <a href="https://www.reddit.com/r/triplej/comments/1adh146/comment/kk16o08/?utm_source=share&amp;utm_medium=web2x&amp;context=3">Super Ego</a> and <a href="https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1hqcl/?utm_source=share&amp;utm_medium=web2x&amp;context=3">Adored</a> all being mentioned as snubs from the hottest 100.</p>
</div>
<div id="surprise-songs" class="section level1">
<h1>Surprise Songs</h1>
<pre><code>##                    Song               Artist rank
## 1             saving up            dom dolla    3
## 2                rumble             skrillex   12
## 3            atmosphere               fisher   14
## 4            back on 74               jungle   17
## 5          eat your man            dom dolla   18
## 6               therapy             budjerah   19
## 7         sorry instead          spacey jane   20
## 8           be your man               g flip   22
## 9           take it off               fisher   23
## 10      rich baby daddy                drake   25
## 11                rough               g flip   26
## 12      dance the night             dua lipa   28
## 13    say yes to heaven         lana del rey   29
## 14    not strong enough            boygenius   30
## 15        get him back!       olivia rodrigo   34
## 16         baby again..           fred again   35
## 17   boy&#39;s a liar pt. 2       pinkpantheress   36
## 18             laced up        hilltop hoods   37
## 19         scary movies            the rions   40
## 20             pedestal        lime cordiale   42
## 21              popular           the weeknd   43
## 22           sweetheart            old mervs   47
## 23          padam padam        kylie minogue   48
## 24            australia               g flip   50
## 25                  ten           fred again   51
## 26     i used to be fun           teen jesus   52
## 27          lookin&#39; out        king stingray   53
## 28   more than you know             blink182   54
## 29   all-american bitch       olivia rodrigo   56
## 30             darkside bring me the horizon   57
## 31                 lost bring me the horizon   58
## 32                  a&amp;w         lana del rey   60
## 33    fall at your feet           peking duk   64
## 34            real life               g flip   65
## 35    leaving the light        genesis owusu   69
## 36               snooze                  sza   70
## 37           speedracer         teenage dads   74
## 38       nobody gets me                  sza   75
## 39            sofa king           royel otis   76
## 40 i don&#39;t wanna be ...                 ruel   77
## 41                bleed        the kid laroi   78
## 42 video killed the ...         teenage dads   79
## 43               7 days               g flip   80
## 44     like a girl does            peach prc   81
## 45                 exes           tate mcrae   82
## 46        the summoning          sleep token   83
## 47     midnight driving         teenage dads   88
## 48            nightmare              polaris   90
## 49 did you know that...         lana del rey   91
## 50  strawberry daydream       pacific avenue   92
## 51          no bad days           the terrys   93
## 52   welcome to the dcc  nothing but thieves   95
## 53         stay blessed        genesis owusu   97
## 54        cool about it            boygenius   98
## 55           i miss you        slowly slowly   99</code></pre>
<p>With 55 snubs, we are going to have 55 surprise songs. There doesn’t seem to be a massive trend here. G flip only made it into my countdown twice, so 5 of their songs are in this list. Its also interesting seeing which conventionally popular songs are part of this list. Boy’s a liar pt. 2 by Pinkpantheress and All American-Bitch which peaked at 2 and 10 on the aria charts were left out in my predictions, even though it predicted similar chart toppers in the top 10.</p>
<p><img src="/post/hottest-100/post-2_files/figure-html/suroprise-comps-1.png" width="672" /></p>
<p>Looking at these plots, it seems that the chart data for these songs didn’t correctly join with the play data from triple J. After cleaning the names, I was hoping that there wouldn’t be too much of a discrepancy. However, in the ARIA charts, “all-american bitch” is listed as “all-american b**ch,” and “boys a liar pt. 2” is listed as “boys a liar”. This kind of discrepancy is probably present throughout my dataset and may have led to some major inaccuracies. However, it is also just part of life when dealing with text data.</p>
</div>
<div id="did-i-do-better-than-warm-tuna" class="section level1">
<h1>Did I do better than Warm Tuna?</h1>
<p>Part of my mission when setting out to make these predictions was to outperform 100 Warm Tunas, who utilize a compilation of social media posts to formulate their predictions.</p>
<pre><code>##                      Song         Artist rank warm_tuna my_rankning
## 1      paint the town red       doja cat    1         9           1
## 2  the worst person alive         g flip    2        11          55
## 3               saving up      dom dolla    3        18          NA
## 4              rhyme dust             mk    4         5          72
## 5                   prada           cass    5        19          90
## 6                 adore u     fred again    6         6          40
## 7    what was i made for?  billie eilish    7         4           3
## 8                    rush    troye sivan    8         1          10
## 9             lovin on me    jack harlow    9        49          17
## 10               chemical    post malone   10        28          14
## 11                vampire olivia rodrigo   11        14           2
## 12                 rumble       skrillex   12         3          NA
## 13              kill bill            sza   13        20           9
## 14             atmosphere         fisher   14        23          NA
## 15                 nanana      peggy gou   15        15           5
## 16               sprinter           dave   16        22           4
## 17             back on 74         jungle   17        13          NA
## 18           eat your man      dom dolla   18        59          NA
## 19                therapy       budjerah   19         8          NA
## 20          sorry instead    spacey jane   20        21          NA</code></pre>
<p>Straight away, I can see that warm tuna did better than me, but by how much?</p>
<p>So, I made up a quick statistic to see how far off our predictions were. This is the sum of the magnitudes of the differences between the predicted score and the actual score. If a song didn’t make the top 100, it’s given the equivalent rank of 101. I then divide this by 100 to get the average deviation for each prediction.</p>
<pre><code>## my score: 36.28</code></pre>
<pre><code>## warm tuna&#39;s score: 26.5</code></pre>
<p>So from these statistics, we can see that my predictions were, on average, about 10 places more off than warm tuna’s.</p>
</div>
<div id="next-year" class="section level1">
<h1>Next Year?</h1>
<p>I reckon this method still has promise, but I need to sort out the name joining issue to ensure that my method is working at its maximum potential. I also want to include genre and artist country into it since it seemed to be an important factor in the final rank that I didn’t account for.</p>
</div>
]]></content>
        </item>
        
        <item>
            <title>Predicting the 2023 Hottest 100</title>
            <link>/2024/01/26/predicting-the-2023-hottest-100/</link>
            <pubDate>Fri, 26 Jan 2024 00:00:00 +0000</pubDate>
            
            <guid>/2024/01/26/predicting-the-2023-hottest-100/</guid>
            <description>Like many Australians, I spent my last Saturday in January getting hyped for the Triple J Hottest 100 countdown. And for the past few years, there has been a project run by 100 Warm Tunas that has been remarkably accurate at predicting the results of the countdown.
Warm Tunas makes predictions by scraping social media posts for people’s votes and then collating them as a sample of all votes. While this method is highly effective, I feel that it misses the point a bit when it comes to understanding why a song is popular.</description>
            <content type="html"><![CDATA[


<p>Like many Australians, I spent my last Saturday in January getting hyped for the Triple J Hottest 100 countdown. And for the past few years, there has been a project run by <a href="https://100warmtunas.com/">100 Warm Tunas</a> that has been remarkably accurate at predicting the results of the countdown.</p>
<p>Warm Tunas makes predictions by scraping social media posts for people’s votes and then collating them as a sample of all votes. While this method is highly effective, I feel that it misses the point a bit when it comes to understanding why a song is popular.</p>
<p>Therefore, this year, I have set out to determine the top songs in the 2023 countdown without relying on anything related to the voting itself.</p>
<div id="my-hypotheses" class="section level2">
<h2>My Hypotheses</h2>
<p>Heading into this, I have a few ideas as to factors that will make a song perform well in the countdown:</p>
<div id="plays-on-triple-j" class="section level3">
<h3>Plays on Triple J</h3>
<p>I feel this factor is pretty self-explanatory. If a song is being played a lot on Triple J, it’s most likely popular with the listener base and will get more votes in the Hottest 100.</p>
</div>
<div id="chart-success" class="section level3">
<h3>Chart Success</h3>
<p>This one is a bit weirder, as I don’t think that just getting to number one in the ARIA charts will make you a top pick for Triple J listeners. Otherwise, the countdown would be topped by the year’s biggest pop hits. If a song is too popular in the mainstream, it seems to fall out of favor with Triple J listeners. However, there are some notable exceptions to this, such as “Bad Guy” by Billie Eilish and “Thrift Shop” by Macklemore, which both took out the top spot in their respective years.</p>
</div>
<div id="time-of-release-and-peak" class="section level3">
<h3>Time of Release and Peak</h3>
<p>This idea is commonly thrown around when talking about the Oscars, so I feel that it’s probably going to be applicable to the Hottest 100 as well. Being at peak popularity when people are voting is probably going to be useful. Similarly, a song that hung around for a long time will probably be voted for more than a song that only hung around for a week.</p>
</div>
</div>
<div id="play-data" class="section level1">
<h1>Play Data</h1>
<p>I gathered the data for all plays on Triple J for the last 8 years from their <a href="https://music.abcradio.net.au/api/v1/plays/search.json?limit=100&amp;offset=0&amp;page=0&amp;station=triplej">API</a>, which left me with a dataset that looks like this:</p>
<p><img src="/post/hottest-100/post_files/figure-html/dataset-plot-1.png" width="672" /></p>
<div id="number-of-plays" class="section level2">
<h2>Number of Plays</h2>
<p>To me, the most obvious indicator of a song’s popularity is the number of plays it receives. So, we can start by examining that.</p>
<p><img src="/post/hottest-100/post_files/figure-html/plays-1.png" width="672" /></p>
<p>These plots give us a good insight into the trends in how Triple J selects songs. We have a lot of songs with almost no plays, which are mostly songs that are being presented to the audience to gauge their reaction. If they become popular, the songs will be played frequently, indicated by the absence of songs with 40-60 plays. However, very few songs receive excessive playtime, with only a handful surpassing 200 plays.</p>
<p>We can also observe the impact of being released early in the year, as these songs have more opportunities to be played throughout the year, resulting in a downward slope for each year.</p>
</div>
<div id="how-total-plays-impact-success" class="section level2">
<h2>How Total Plays Impact Success</h2>
<p><img src="/post/hottest-100/post_files/figure-html/plays-vs-success-1.png" width="672" /></p>
<p>Looking at the rankings, we can see that the total number of plays doesn’t have a massive impact on performance. A song can have five plays or a hundred, and it seems to have a similar outcome in the rankings.</p>
<p>There is a slight downward trend for songs getting over 120 plays, as these are the absolute most played songs for the year. However, this status still doesn’t guarantee a top spot.</p>
</div>
<div id="accounting-for-time" class="section level2">
<h2>Accounting for Time</h2>
<p>A thought I had while looking at the absolute play data is that it disproportionately rewards songs that were released earlier in the year.</p>
<p>To address this, I have compiled some statistics that consider the peak of the songs, which should eliminate any advantage for being released at the beginning of the year.</p>
<p><img src="/post/hottest-100/post_files/figure-html/plays-vs-success-accounting-for-time-1.png" width="672" /></p>
<p>Again, we can see that there is some useful information, with the peak plays per week showing that songs which have a big peak generally perform well in the final rankings. However, as with the absolute count of plays, there doesn’t seem to be a hard and fast rule.</p>
</div>
</div>
<div id="chart-success-1" class="section level1">
<h1>Chart Success</h1>
<p>The ARIA charts collate music sales and streaming data within Australia and produce a weekly list of the top 50 most popular songs. A GitHub user has been kind enough to <a href="https://raw.githubusercontent.com/caseybriggs/ARIA-charts/main/single_charts.csv">compile all of these lists</a>, so we can simply load them and compare the chart results to a song’s position in the Hottest 100.</p>
<p><img src="/post/hottest-100/post_files/figure-html/Chart-1.png" width="672" /></p>
<p>The first thing to note is that these plots are much sparser than the rest. This is because many songs played on Triple J don’t make it into the top 50 at all, even though they make it into the Hottest 100.</p>
<p>For the songs that did make it into the ARIA charts and hung around, they consistently performed well in the countdown. Examples include “Bad Guy” by Billie Eilish and “Dance Monkey” by Tones and I, which claimed the 1st and 4th spots in their respective years.</p>
<p>However, the predictive power of this statistic is again quite limited. Many songs that performed well in the Hottest 100 had poor chart success. For instance, “Redbone” by Childish Gambino took the 5th spot in 2015 despite only spending a single week in the charts at rank 42.</p>
<p><img src="/post/hottest-100/post_files/figure-html/chart-did-it-make-it-1.png" width="672" /></p>
<p>From this chart, we can see that songs that make the charts are outperforming songs that don’t. But more importantly, it shows us that making the charts is not a deal-breaker on whether or not a song will perform well in the Hottest 100.</p>
</div>
<div id="timing" class="section level1">
<h1>Timing</h1>
<p>Another thing I wanted to look at was when and how the songs peaked in the play data. Maybe being the popular song would help the song perform around the time that voting is open, which may help with its performance in the final rankings.</p>
<p><img src="/post/hottest-100/post_files/figure-html/week-of-peak-1.png" width="672" /></p>
<p>Looking at the above plots, we can see that the week of release or peak really doesn’t matter when looking at the final results.</p>
<p>I went on to see if the shape of the peaks looks different for well-performing songs versus poorly performing songs, and again, nothing seems particularly interesting or different between the two.</p>
<p><img src="/post/hottest-100/post_files/figure-html/multiline-1.png" width="672" /></p>
</div>
<div id="where-we-are-going-wrong" class="section level1">
<h1>Where we are going wrong</h1>
<p>So it seems that all of my hypotheses are incorrect, and I believe the reason for this is that there is too much variation among the top 100. This is because these songs are already considered the best of the year from a pool of nearly 4000.</p>
<p><img src="/post/hottest-100/post_files/figure-html/overall-1.png" width="672" /></p>
<p>Looking at this plot, we can see right away that a song that made the Hottest 100 got more plays than those that didn’t, but also that plenty of songs that didn’t make the 100 got a comparable number of plays.</p>
</div>
<div id="screw-it-xgboost" class="section level1">
<h1>Screw it XGBoost</h1>
<p>I think the direction to go here is to see if we can use ML to find any trends that aren’t showing up in the plots.</p>
<p>To do this, we are going to use XGBoost to train a model to predict the rank of the song using all the stats I wrote out above. The only thing I changed was taking the first play data and setting it to be the month rather than the day to reduce overfitting. For any song that didn’t make it into the 100, I set the rank to be 101, as it could be the 101st most popular song that year.</p>
<p><img src="/post/hottest-100/post_files/figure-html/boost-train-1.png" width="672" /></p>
<p>A nice thing about XGBoost is that it can provide insight into the most important factors it uses to predict the results. From the above plots, we can see that the peak of the song on triple J and its total plays contribute significantly to the predictive power.</p>
<p>Interestingly, the chart scores seem to have little effect. However, this can be justified by considering the fact that many songs that make the top 100 never make the charts.</p>
<p>Now that we have the model, we can evaluate its performance in predicting the Hottest 100 by applying it to the play data from 2022.</p>
<div id="predicted-countdown" class="section level3">
<h3>2022 Predicted Countdown</h3>
<pre><code>##                         Song          Artist Actual
## 1                   b.o.t.a.      eliza rose      2
## 2                say nothing           flume      1
## 3              glimpse of us            joji     10
## 4                  bad habit      steve lacy      4
## 5                first class     jack harlow     12
## 6            about damn time           lizzo      7
## 7                 sitting up     spacey jane      6
## 8               get inspired   genesis owusu     17
## 9  in the wake of your leave  gang of youths      9
## 10                     shirt             sza     20
## 11                 hardlight     spacey jane      3
## 12          stars in my eyes ball park music      8
## 13             stranger days          skegss     19
## 14            god is a freak       peach prc     16
## 15      it&#39;s been a long day     spacey jane      5
## 16            thousand miles   the kid laroi     33
## 17       backseat of my mind     thelma plum     21
## 18                2 be loved           lizzo     36
## 19             facts of life   lime cordiale     15
## 20                      doja     central cee     39</code></pre>
</div>
<div id="real-countdown" class="section level3">
<h3>2022 Real Countdown</h3>
<pre><code>##                         Song          Artist Predicted
## 1                say nothing           flume         2
## 2                   b.o.t.a.      eliza rose         1
## 3                  hardlight     spacey jane        11
## 4                  bad habit      steve lacy         4
## 5       it&#39;s been a long day     spacey jane        15
## 6                 sitting up     spacey jane         7
## 7            about damn time           lizzo         6
## 8           stars in my eyes ball park music        12
## 9  in the wake of your leave  gang of youths         9
## 10             glimpse of us            joji         3
## 11                  gay 4 me          g flip        29
## 12               first class     jack harlow         5
## 13                  new gold        gorillaz        24
## 14                   delilah      fred again        27
## 15             facts of life   lime cordiale        19
## 16            god is a freak       peach prc        14
## 17              get inspired   genesis owusu         8
## 18             stranger days          skegss        13
## 19                     shirt             sza        10
## 20       backseat of my mind     thelma plum        17</code></pre>
<p>From this, I reckon the model is doing pretty well, so lets have a look at my final predictions for the hottest 100 of 2023.</p>
</div>
</div>
<div id="my-final-predictions" class="section level1">
<h1>My Final Predictions</h1>
<p>The list below seems pretty reasonable, with Doja Cat taking the top spot and my pick for number one, Rush, sitting in 10th. There seems to be a big lean towards pop and a lack of your classic Triple J-style indie rockers, but that might just be the turnout for this year.</p>
<pre><code>##                          Song                Artist
## 1          paint the town red              doja cat
## 2                     vampire        olivia rodrigo
## 3        what was i made for?         billie eilish
## 4                    sprinter                  dave
## 5                      nanana             peggy gou
## 6                   love type              poolclvb
## 7                 green honda                 benee
## 8                   super ego          babe rainbow
## 9                   kill bill                   sza
## 10                       rush           troye sivan
## 11                     greedy            tate mcrae
## 12                  strangers           kenya grace
## 13    sweat you out my system                  maya
## 14                   chemical           post malone
## 15                     adored            royel otis
## 16            bad idea right?        olivia rodrigo
## 17                lovin on me           jack harlow
## 18                    houdini              dua lipa
## 19             got me started           troye sivan
## 20               barbie world           nicki minaj
## 21           lost without you             san cisco
## 22               super-vision                  dice
## 23                agora hills              doja cat
## 24               blak britney          miss kaninna
## 25                  glue song           beabadoobee
## 26                   ruthless         hooligan hefs
## 27                  attention              doja cat
## 28                 james dean          tash sultana
## 29        never felt so alone              labrinth
## 30      my love mine all mine                mitski
## 31                      water                  tyla
## 32            still have room            hockey dad
## 33                do it again                 benee
## 34                 trippin up     the jungle giants
## 35           i wish you roses            kali uchis
## 36              dash of speed            rum jungle
## 37                   too much         the kid laroi
## 38                 eyes ahead                  dice
## 39  spin me like your records        pacific avenue
## 40                    adore u            fred again
## 41                   dogtooth                 tyler
## 42             pets and drugs            the rubens
## 43          imposter syndrome         lime cordiale
## 44             into your room     holly humberstone
## 45                 love again         the kid laroi
## 46                         up                   lee
## 47                    pegasus            arlo parks
## 48                  exploding         angie mcmahon
## 49                  stockholm                  dice
## 50                    calling          metro boomin
## 51               must be nice                  ruel
## 52                better love            eliza rose
## 53               your funeral                  maya
## 54          don&#39;t let me down         gus dapperton
## 55     the worst person alive                g flip
## 56                  conceited            lola young
## 57                  messed up             holy holy
## 58           lost in the rush              telenova
## 59               candle flame                jungle
## 60          one of your girls           troye sivan
## 61                    minivan             the rions
## 62            perfect for you             peach prc
## 63               prescription             remi wolf
## 64                     change                laurel
## 65                      angel        pinkpantheress
## 66                     sinner the last dinner party
## 67                    midwest             vacations
## 68                pretty girl             ice spice
## 69                good enough                g flip
## 70         take what you want             the rions
## 71              i wanna dance            royel otis
## 72                 rhyme dust                    mk
## 73              boys light up             chillinit
## 74          make up your mind                cordae
## 75                 viper room             thornhill
## 76                 weightless            arlo parks
## 77                 letting go         angie mcmahon
## 78          can&#39;t play myself                skepta
## 79             black mascara.                  raye
## 80                 feel alive                   cat
## 81                   tied up!         genesis owusu
## 82            fine day anthem              skrillex
## 83     we don&#39;t talk about it           thelma plum
## 84             mrs. hollywood                  gojo
## 85              am i dreaming          metro boomin
## 86                    comma&#39;s               onefour
## 87                       lola                  maya
## 88    it&#39;s cool to be in love         greta stanley
## 89       since i have a lover                 6lack
## 90                      prada                  cass
## 91              lil boo thang          paul russell
## 92            nothing matters the last dinner party
## 93               going kokomo            royel otis
## 94                all my life              lil durk
## 95               brain freeze northeast party house
## 96                    healing      molly millington
## 97                     sticky                  kito
## 98                     rakata     the jungle giants
## 99           lost the breakup         maisie peters
## 100               f u goodbye             peach prc</code></pre>
</div>
]]></content>
        </item>
        
        <item>
            <title>Making my ODE solver solve ODEs</title>
            <link>/2024/01/12/making-my-ode-solver-solve-odes/</link>
            <pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate>
            
            <guid>/2024/01/12/making-my-ode-solver-solve-odes/</guid>
            <description>After writing out the last post where I wrote out a python library for using an improved version of Euler’s method to solve ODEs. But so far, we haven’t been solving ODES, instead we have just been taking an initial value and iterating it over the length of a domain. To To make the ODE estimator work, we need to ensure that the conditions of the ODE are met at each step.</description>
            <content type="html"><![CDATA[


<p>After writing out the <a href="/2023/12/29/making-a-python-library-to-solve-differential-equations/">last post</a> where I wrote out a python library for using an improved version of Euler’s method to solve ODEs. But so far, we haven’t been solving ODES, instead we have just been taking an initial value and iterating it over the length of a domain. To To make the ODE estimator work, we need to ensure that the conditions of the ODE are met at each step.</p>
<div id="simplifying-odes-constant-linear-odes" class="section level1">
<h1>Simplifying ODEs: Constant-Linear ODEs</h1>
<p>ODEs are often categorized as linear or non-linear. Linear ODEs take the form <span class="math inline">\(a_0(x)y + a_1(x)y&#39; + ... + a_n(x)y^{n} = b(x)\)</span>, with both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> representing functions of <span class="math inline">\(x\)</span>, while Non-linear equations are all the others. In our solver’s context, we’ll concentrate on a subset I’ve termed “constant-linear” ODEs, characterized by constant coefficients for <span class="math inline">\(y\)</span> terms and a linear function of <span class="math inline">\(x\)</span> for <span class="math inline">\(b\)</span>. Specifically, a constant-linear ODE looks like <span class="math inline">\(a_0y + a_1y&#39; + ... + a_ny^{n} = bx + c\)</span>.<br />
This may seem like a very restrictive requirement, but there are many famous examples of this kind of equation including:</p>
<ol style="list-style-type: decimal">
<li><p>Simple Harmonic Motion:
<span class="math display">\[ y&#39;&#39; + \omega^2 y = 0 \]</span></p></li>
<li><p>Radioactive Decay:
<span class="math display">\[ \frac{dy}{dt} = -\lambda y \]</span></p></li>
<li><p>RC Circuit Equation:
<span class="math display">\[ y&#39; + \frac{1}{RC} y = 0 \]</span></p></li>
<li><p>Damped Harmonic Oscillator:
<span class="math display">\[ y&#39;&#39; + 2\gamma y&#39; + \omega_0^2 y = 0 \]</span></p></li>
<li><p>Heat Equation (One-Dimensional):
<span class="math display">\[ u&#39;&#39; - \frac{1}{\alpha} u&#39;= 0 \]</span></p></li>
<li><p>Exponential Growth or Decay:
<span class="math display">\[ y&#39; = ky \]</span></p></li>
</ol>
</div>
<div id="a-quick-diversion-odes-in-vector-space" class="section level1">
<h1>A Quick Diversion: ODEs in Vector Space</h1>
<p>Pivoting for a moment, I want to take a quick moment to reframe how we are imagining ODEs. Most of the time, we see ODEs as curves in space and/or time, but I want to reframe them as planes in a vector space.</p>
<p>Each point in this vector space describes the state of a point along a curve, such that a values of the vector give:</p>
<p><span class="math display">\[\begin{bmatrix}
1\\
x\\
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix} 
\]</span></p>
<p>This means that an ODE can be defined by a plane that contains all the points which meet the requirements of the ODE.</p>
<p>For example, for the equation <span class="math inline">\(y&#39; = 2x\)</span> this plane looks like:</p>
<p><img src="/post/taylor-series/post-3_files/figure-html/vector-space-1.png" width="614" /></p>
<p>Then a specific solution to the ODE exists as a curve that sits on this plane. For example, for the IVP that starts at (0,0), the solution follows this curve:</p>
<p><img src="/post/taylor-series/post-3_files/figure-html/vector-space-line-3.png" width="672" /></p>
<div id="but-why-does-this-matter" class="section level2">
<h2>But Why Does This Matter</h2>
<p>The reason that we want to reframe ODEs in this way is because of the following fact:</p>
<p><strong>For all constant-linear ODEs, we can express the ODE as a matrix such that applying it to any point in the vector space would map any point to a valid point on the curve defined by the ODE</strong><br />
</p>
<p>Looking at the equations above, these matrices (<span class="math inline">\(T\)</span>) are:</p>
<ol style="list-style-type: decimal">
<li><p>Simple Harmonic Motion:
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; -\omega^2 &amp; 0 &amp; 0\\
\end{bmatrix}
\]</span></p></li>
<li><p>Radioactive Decay:
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; -\lambda &amp; 0\\
\end{bmatrix}\]</span></p></li>
<li><p>RC Circuit Equation:
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; \frac{-1}{RC} &amp; 0\\
\end{bmatrix}\]</span></p></li>
<li><p>Damped Harmonic Oscillator:
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; -\omega^2 &amp; -2\gamma &amp; 0\\
\end{bmatrix}\]</span></p></li>
<li><p>Heat Equation (One-Dimensional):
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; \frac{1}{\alpha} &amp; 0\\
\end{bmatrix}\]</span></p></li>
<li><p>Exponential Growth or Decay:
<span class="math display">\[T = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; k &amp; 0\\
\end{bmatrix}\]</span></p></li>
</ol>
</div>
<div id="using-these-to-fit-odes" class="section level2">
<h2>Using these to fit ODEs</h2>
<p>Now that we can express the ODEs in the form of a matrix, we can implement these matriexies in the ODE solver package to make the solution fit the ode.
It’s important here to note that I’ve diverted from my old definitions of <span class="math inline">\(Y\)</span> here, where the first element of the vector is <span class="math inline">\(y(x)\)</span>.</p>
<p>To make a step in the approximation we use the following equation:</p>
<p><span class="math display">\[ \begin{bmatrix}
1 \\
x+h \\ 
y(x+h)\\
y&#39;(x+h)\\
y&#39;&#39;(x+h)\\
...\\
y^{n}(x+h)\\
\end{bmatrix} =  S \cdot \begin{bmatrix}
1 \\
x\\
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix}
\epsilon \]</span></p>
<p>Where <span class="math inline">\(S\)</span> is:
<span class="math display">\[ \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
h &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; \frac{h}{1!} &amp; \frac{h^2}{2!} &amp;  ... &amp; \frac{h^n}{n!}\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; \frac{h}{1!} &amp;  ... &amp; \frac{h^{n-1}}{(n-1)!}\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp;  ... &amp; \frac{h^{n-2}}{(n-2)!}\\
... &amp; ... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;  ... &amp; 1\\
\end{bmatrix}\]</span></p>
<p>When making this step, the error in the approximation will move the point away from the plane that contains all valid solutions to the ODE, and therefore we will have to snap it back using one of the transformation matrices (<span class="math inline">\(T\)</span>).</p>
<p>Implementing this method in our python library:</p>
<pre class="python"><code>def expanded_euler(dims, h):
    step_matrix = np.zeros((dims, dims))
    for i in range(dims):
        for j in range(i, dims):
            # Is 1, and h at j-i =0, 1 respectively
            step_matrix[i, j] = h ** (j - i) / math.factorial(j - i)
    expanded_matrix = add_x_and_1(step_matrix, h)
    return expanded_matrix


def add_x_and_1(original_matrix, h):
    new_size = len(original_matrix) + 2
    new_matrix = np.zeros((new_size, new_size), dtype=original_matrix.dtype)

    # Set the 2x2 top left matrix
    new_matrix[0:2, 0:2] = [[1, 0], [h, 1]]

    # Copy the original matrix to the bottom right of the new matrix.
    new_matrix[2:, 2:] = original_matrix
    return new_matrix


def linear(y, step_matrix_generator, transformation_matrix, steps=10, h=0.1):
    dims = len(y) - 2
    step_matrix = transformation_matrix @ step_matrix_generator(dims, h)
    output_list = []

    y_n = y.copy()
    i = 0
    while i &lt; steps:
        y_n = step_matrix @ y_n
        output_list.append(y_n)
        i += 1</code></pre>
<p>Bind this machinery together, and you get a tool capable of tackling the initial example of <span class="math inline">\(y&#39; = 2x\)</span> passing through the point (0,0):</p>
<pre class="python"><code>init_y = [1,0,0,0] #[1,x,y,y&#39;]
transformation_matrix = np.array([
   [ 1,0,0,0 ],
   [ 0,1,0,0 ],
   [ 0,0,1,0 ],
   [ 0,2,0,0 ]
])
solution = linear(
    init_y,
    expanded_euler,
    transformation_matrix,
    steps=100, h=0.01)</code></pre>
<p><img src="/post/taylor-series/post-3_files/figure-html/example_plo-5.png" width="672" /></p>
</div>
</div>
<div id="whats-next" class="section level1">
<h1>What’s Next?</h1>
<p>This method seems to work pretty well and follows the true solution pretty closely. I’m going to stop here for now but there are many things on my wishlist that I want to build in later posts. This includes:</p>
<ul>
<li>Solving IVPs which aren’t constant-linear</li>
<li>Solving BVPs</li>
<li>Applying this method to PDEs</li>
</ul>
<p>Stay tuned for more posts in this series where I try to implement these features into my solver!</p>
</div>
]]></content>
        </item>
        
        <item>
            <title>DIY Dev-Containers</title>
            <link>/2024/01/07/diy-dev-containers/</link>
            <pubDate>Sun, 07 Jan 2024 00:00:00 +0000</pubDate>
            
            <guid>/2024/01/07/diy-dev-containers/</guid>
            <description>Why we use Dev-Containers What I want The Beginnings Docker In Docker Secrets Management Portability Wrapping it up Like most developers, I spend an inordinate amount of time dealing with my local installations and dependencies. When working on multiple projects, it is not uncommon to encounter conflicting versions of dependencies, and while virtual environments and package managers like Node Package Manager help to mitigate this issue, they often fall short.</description>
            <content type="html"><![CDATA[

<div id="TOC">
<ul>
<li><a href="#why-we-use-dev-containers">Why we use Dev-Containers</a></li>
<li><a href="#what-i-want">What I want</a></li>
<li><a href="#the-beginnings">The Beginnings</a></li>
<li><a href="#docker-in-docker">Docker In Docker</a></li>
<li><a href="#secrets-management">Secrets Management</a></li>
<li><a href="#portability">Portability</a></li>
<li><a href="#wrapping-it-up">Wrapping it up</a></li>
</ul>
</div>

<p>Like most developers, I spend an inordinate amount of time dealing with my local installations and dependencies. When working on multiple projects, it is not uncommon to encounter conflicting versions of dependencies, and while virtual environments and package managers like Node Package Manager help to mitigate this issue, they often fall short.</p>
<div id="why-we-use-dev-containers" class="section level1">
<h1>Why we use Dev-Containers</h1>
<p>A common solution to these issues is the use of ‘dev-containers’, which have mostly been popularized by VS Code as a way to have your dependencies exist exclusively inside a Docker container, and then attach an editor to it to make your changes. Sounds great, but unfortunately for me, I have years of using Vim keybindings built into my muscle memory, so there’s little chance of me changing my editor. So instead, I thought, why not just rebuild the dev containers for Vim?</p>
</div>
<div id="what-i-want" class="section level1">
<h1>What I want</h1>
<p>So let’s quickly scope out this project. In my development containers, I want:</p>
<ul>
<li>Isolated environments</li>
<li>Vim with my configuration built-in</li>
<li>Integration with common CLI tools</li>
<li>The ability to use Docker from inside the container</li>
<li>Secrets management (not having to re-authenticate all my tools every time I open up a container)</li>
<li>Transportability between various Unix machines</li>
</ul>
</div>
<div id="the-beginnings" class="section level1">
<h1>The Beginnings</h1>
<p>So after taking a quick look around my system, I have come up with this initial Dockerfile for my development container:</p>
<pre class="dockerfile"><code>FROM ubuntu as setter_upper

ARG DEBIAN_FRONTEND=noninteractive
ENV TZ=Australia/Melbourne
# Enviroment Installs
RUN apt-get update &amp;&amp; apt-get install -y \
   curl git python3 python3-pip apt-transport-https \
   ca-certificates software-properties-common  libpq-dev \
   build-essential autoconf automake libtool

#Install Docker
RUN curl -fsSL https://get.docker.com -o install-docker.sh
RUN sh install-docker.sh


# Install GH CLI
RUN curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
&amp;&amp; chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
&amp;&amp; echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main&quot; | tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null \
&amp;&amp; apt update \
&amp;&amp; apt install gh -y

# git
#RUN gh auth setup-git
run git config --global user.name &quot;Fonzzy1&quot;
run git config --global user.email &quot;alfiechadwick@hotmail.com&quot;

# Set the base work dir
WORKDIR /src

# Set the mount point as the safe dir
RUN git config --global --add safe.directory /src

# Vim Setup
FROM setter_upper as vim

# Enviroment Installs
RUN apt-get update &amp;&amp; apt-get install -y software-properties-common
RUN add-apt-repository ppa:jonathonf/vim
RUN apt-get update

# Install the rest of the dependencies
RUN apt-get install -y \
    tig \
    fzf \
    pkg-config \
    texlive \
    r-base \
    pandoc \
    texlive-latex-extra \
    libcurl4-openssl-dev \
    libssl-dev \
    libxml2-dev \
    libfontconfig1-dev \
    libharfbuzz-dev \
    libfribidi-dev \
    libfreetype6-dev \
    libpng-dev \
    libtiff5-dev \
    libjpeg-dev \
    r-cran-tidyverse \
    vim-gtk3

#Install Ctags
RUN curl -L https://github.com/thombashi/universal-ctags-installer/raw/master/universal_ctags_installer.sh | bash

# Install node
RUN set -uex
RUN mkdir -p /etc/apt/keyrings
RUN curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
RUN echo &quot;deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main&quot; |  tee /etc/apt/sources.list.d/nodesource.list
RUN apt-get update &amp;&amp; apt-get install nodejs -y;


# Install the python packages
RUN pip install black pipreqs pgcli awscli socli

# Install npm packages
RUN npm install --save-dev --global prettier

# Download and Install Vim-Plug
RUN curl -fLo /root/.vim/autoload/plug.vim --create-dirs \
    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim

# Install ACT extention
RUN mkdir -p /root/.local/share/gh/extensions/gh-act
RUN curl -L -o /root/.local/share/gh/extensions/gh-act/gh-act \
    &quot;https://github.com/nektos/gh-act/releases/download/v0.2.57/linux-amd64&quot;
RUN chmod +x /root/.local/share/gh/extensions/gh-act/gh-act


# Install R packages, tidyvverse is installed with apt
RUN R -e  &quot;install.packages(&#39;rmarkdown&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;install.packages(&#39;reticulate&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;install.packages(&#39;blogdown&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;blogdown::install_hugo()&quot;
RUN R -e  &quot;install.packages(&#39;readxl&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;install.packages(&#39;knitr&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;install.packages(&#39;tinytex&#39;,  Ncpus = 6)&quot;
RUN R -e  &quot;install.packages(&#39;languageserver&#39;,  Ncpus = 6)&quot;

# Bring in the vim config
COPY vim /root/.vim
#Copy in the dotfiles
COPY dotfiles /root

# Install Vim Plugins
RUN vim +PlugInstall +qall

# Install COC plugins
RUN mkdir -p /root/.config/coc/extensions &amp;&amp; \
    echo &#39;{&quot;dependencies&quot;:{}}&#39; &gt; /root/.config/coc/extensions/package.json &amp;&amp; \
    grep &#39;let g:coc_global_extensions&#39; /root/.vim/config/coc.vim | \
    sed &quot;s/.*\[//; s/\].*//; s/&#39;//g; s/, /\n/g&quot; | \
    while read -r extension; do \
        echo &quot;Installing coc extension: $extension&quot; &amp;&amp; \
        cd /root/.config/coc/extensions &amp;&amp; \
        npm install &quot;$extension&quot; --install-strategy=shallow --save; \
    done

CMD vim</code></pre>
<p>I won’t bother explaining most of it since it’s really just a heap of install statements, but here are some of the interesting parts:</p>
<ul>
<li>I needed to add the WORKDIR to the list of safe directories for git since if I mount the file, the ownership will be wrong.</li>
<li>I needed to manually install the gh act extension as you can’t do it normally without authenticating with a gh token, something I don’t want to do in a public container.</li>
<li>Coc Extensions needed to be manually installed to prevent them from installing every time I started the container. Just calling <code>Vim +CocInstall</code> didn’t work because it’s an async process.</li>
</ul>
<p>So at this point, I have the first three of my requirements done. Because I’m using Docker, I have an isolated environment every time I boot up the container. By copying over my Vim config files, I have my Vim config baked in, and with some of the commands in the Dockerfile, I am able to have it set up. Finally, by installing a heap of CLI tools, I am able to do most of my work from inside the Vim terminal.</p>
</div>
<div id="docker-in-docker" class="section level1">
<h1>Docker In Docker</h1>
<p>The next thing to tick off the list is being able to run Docker commands from within the container. Although I have installed Docker, running any Docker command inside the container will say the daemon isn’t running.</p>
<p>I could put in a lot of work to give the container the ability to create its own containers, but that would be a real pain. Instead, I can simply mount the Docker daemon onto the container, so that running Docker commands inside the container will invoke the system Docker.</p>
<p>To accomplish this, I can execute the container using the following command:</p>
<pre class="bash"><code>docker run -it -v /var/run/docker.sock:/var/run/docker.sock fonzzy1/vim</code></pre>
</div>
<div id="secrets-management" class="section level1">
<h1>Secrets Management</h1>
<p>The next thing to implement is secrets management. I currently have all of these stored in config files in my home directory, which isn’t best practice in a Docker container that I want to make public. Instead, I can put all my secrets in a .env file and reference them in the Docker container. This can be done using the –env-file flag when running my Docker container.</p>
</div>
<div id="portability" class="section level1">
<h1>Portability</h1>
<p>The final goal on my list is to make the container portable between my multiple machines. This is achieved through the use of Docker Hub, which will allow me to download the image from Docker Hub. The only other thing I need is to ensure that Docker is set up on the other machine. For this, I have written a quick script to handle the setup process.</p>
<pre class="bash"><code>#!/bin/bash
set -e

# Dot Progress Indicator
progress() {
    local pid=$2 # PID of the process we&#39;re waiting for
    local text=$1
    local delay=2 # 2-second delay between dots
    local dot=&quot;.&quot;

    printf &quot;%s:&quot; &quot;$text&quot;
    while [ &quot;$(ps a | awk &#39;{print $1}&#39; | grep -w $pid)&quot; ]; do
        printf &quot;%s&quot; &quot;$dot&quot;
        sleep $delay
    done
    printf &quot; Done!\n&quot;
}

progress &quot;Updating package list&quot; $(sudo apt-get update &gt; /dev/null 2&gt;&amp;1 &amp; echo $!)

progress &quot;Installing Useful Packages&quot; $(sudo apt-get install -y curl &gt; /dev/null 2&gt;&amp;1 &amp; echo $!)

progress &quot;Fetching Docker Install Script&quot; $(curl -fsSL https://get.docker.com -o install-docker.sh &gt; /dev/null 2&gt;&amp;1 &amp; echo $!)

progress &quot;Installing Docker&quot; $(sudo sh install-docker.sh &gt; /dev/null 2&gt;&amp;1 &amp; echo $!)

progress &quot;Adding the current user to the Docker group&quot; $(sudo usermod -aG docker $USER &gt; /dev/null 2&gt;&amp;1 &amp; echo $!)

progress &quot;Pulling Image&quot; docker pull fonzzy1/vim

echo &quot;Setup complete!&quot;</code></pre>
</div>
<div id="wrapping-it-up" class="section level1">
<h1>Wrapping it up</h1>
<p>My so now I have my dev containers running, my only gripe is the stupidly long docker commands that I need to type out to get it running, such as:</p>
<pre class="bash"><code>current_dir=&quot;$(pwd)&quot;
dir_name=&quot;$(basename &quot;$current_dir&quot;)&quot;

docker run -it \
  --env-file ~/.env \
  --net=host \
  --rm \
  -v &quot;$current_dir:/$(dir_name)&quot; \
  -w &quot;/$dir_name&quot; \
  -v /var/run/docker.sock:/var/run/docker.sock \
  fonzzy1/vim \
  /bin/bash -c &quot;gh auth setup-git; git config --global --add safe.directory /$dir_name; vim&quot;</code></pre>
<p>So I decided to make this into a little Python script that allows me to quickly run these commands. I also added an integration with <code>gh</code> that lets me clone repos in order to edit them on the fly.</p>
<pre class="python"><code>#!/bin/python3
import subprocess
import argparse
import os


def run_local(args):
    &quot;&quot;&quot;
    Runs a command in a Docker container with the current directory mounted.

    Args:
        args (argparse.Namespace): The command-line arguments.

    Returns:
        None
    &quot;&quot;&quot;
    current_dir = subprocess.run([&quot;pwd&quot;], capture_output=True, text=True).stdout.strip()
    dir_name = current_dir.split(&quot;/&quot;)[-1]  # Get the name of the current directory

    subprocess.run(
        [
            &quot;docker&quot;,
            &quot;run&quot;,
            &quot;-it&quot;,
            &quot;--env-file&quot;,
            os.path.expanduser(&quot;~/.env&quot;),
            &quot;--net=host&quot;,
            &quot;--rm&quot;,
            &quot;-v&quot;,
            f&quot;{current_dir}:/{dir_name}&quot;,  # Mount to a directory with the same name
            &quot;-w&quot;,
            f&quot;/{dir_name}&quot;,  # Set the working directory
            &quot;-v&quot;,
            &quot;/var/run/docker.sock:/var/run/docker.sock&quot;,
            &quot;fonzzy1/vim&quot;,
            &quot;/bin/bash&quot;,
            &quot;-c&quot;,
            f&quot;gh auth setup-git; git config --global --add safe.directory /{dir_name}; vim&quot;,
        ]
    )


def run_gh(args):
    &quot;&quot;&quot;
    Runs a command for cloning a GitHub repository in a Docker container.

    Args:
        args (argparse.Namespace): The command-line arguments.

    Returns:
        None
    &quot;&quot;&quot;
    name = args.repo.replace(&quot;/&quot;, &quot;-&quot;)
    repo = args.repo.split(&quot;/&quot;)[-1] if &quot;/&quot; in args.repo else args.repo
    command = f&quot;gh auth setup-git; gh repo clone {args.repo} /{repo}; &quot;

    # Additional git command based on input parameters
    if args.branch:
        command += f&quot;git switch {args.branch}; &quot;
    elif args.pullrequest:
        command += f&quot;gh pr checkout {args.pullrequest}; &quot;
    elif args.checkout:
        command += f&quot;git checkout -b {args.checkout}; git push --set-upstream origin {args.checkout}; &quot;

    # Update submodules if any
    command += &quot;git submodule update --init; vim; &quot;

    # Check for unpushed or uncommitted changes before exiting Vim
    check_changes_command = &#39; \
        CHANGES=$(git status --porcelain); \
        UPSTREAM_CHANGES=$(git cherry -v); \
        if [ -n &quot;$CHANGES&quot; ] || [ -n &quot;$UPSTREAM_CHANGES&quot; ]; then \
            vim -c \&#39;:G | only\&#39;; \
        fi&#39;

    # Final combined command
    final_command = command + check_changes_command

    subprocess.run(
        [
            &quot;docker&quot;,
            &quot;run&quot;,
            &quot;-it&quot;,
            &quot;--env-file&quot;,
            os.path.expanduser(&quot;~/.env&quot;),
            &quot;--name&quot;,
            name,
            &quot;--net=host&quot;,
            &quot;--rm&quot;,
            &quot;-w&quot;,
            f&quot;/{repo}&quot;,
            &quot;-v&quot;,
            &quot;/var/run/docker.sock:/var/run/docker.sock&quot;,
            &quot;fonzzy1/vim&quot;,
            &quot;/bin/bash&quot;,
            &quot;-c&quot;,
            final_command,
        ]
    )


if __name__ == &quot;__main__&quot;:
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(title=&quot;commands&quot;, dest=&quot;command&quot;)

    local_parser = subparsers.add_parser(
        &quot;local&quot;, help=&quot;Run command for a container with local directory&quot;
    )
    local_parser.set_defaults(func=run_local)

    gh_parser = subparsers.add_parser(&quot;gh&quot;, help=&quot;Run command for cloning a repo&quot;)
    gh_parser.add_argument(&quot;repo&quot;, help=&quot;Specify the repository for cloning&quot;)
    gh_parser.set_defaults(func=run_gh)
    gh_parser.add_argument(&quot;-b&quot;, &quot;--branch&quot;, help=&quot;The branch to checkout&quot;)
    gh_parser.add_argument(
        &quot;-p&quot;, &quot;--pullrequest&quot;, help=&quot;The pull request number to checkout&quot;
    )
    gh_parser.add_argument(&quot;-c&quot;, &quot;--checkout&quot;, help=&quot;Checkout a new branch from main&quot;)

    args = parser.parse_args()
    args.func(args)</code></pre>
</div>
]]></content>
        </item>
        
        <item>
            <title>Making a Python Library to solve differential Equations</title>
            <link>/2023/12/29/making-a-python-library-to-solve-differential-equations/</link>
            <pubDate>Fri, 29 Dec 2023 00:00:00 +0000</pubDate>
            
            <guid>/2023/12/29/making-a-python-library-to-solve-differential-equations/</guid>
            <description>After having the initial idea I wrote up in a previous post, I thought it was a good idea to turn it into a python library so that I can use it as part of my other projects.
It also gives me a chance to see numerically how well the new method works compared to the Euler method.
First Steps So in the last post I set out the method such that: \[ \begin{bmatrix} y(x+h)\\ y&amp;#39;(x+h)\\ y&amp;#39;&amp;#39;(x+h)\\ .</description>
            <content type="html"><![CDATA[


<p>After having the initial idea I wrote up in a <a href="/2023/12/18/using-taylor-series-to-improve-the-euler-method/">previous post</a>, I thought it was a good idea to turn it into a python library so that I can use it as part of my other projects.</p>
<p>It also gives me a chance to see numerically how well the new method works compared to the Euler method.</p>
<div id="first-steps" class="section level1">
<h1>First Steps</h1>
<p>So in the last post I set out the method such that:
<span class="math display">\[ \begin{bmatrix}
y(x+h)\\
y&#39;(x+h)\\
y&#39;&#39;(x+h)\\
...\\
y^{n}(x+h)\\
\end{bmatrix} =  S \cdot \begin{bmatrix}
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix} + \epsilon \]</span></p>
<p>In the Euler method, <span class="math inline">\(S\)</span> is:
<span class="math display">\[\begin{bmatrix}
1 &amp; h &amp; 0 &amp;  ... &amp; 0\\
0 &amp; 1 &amp; h &amp;  ... &amp; 0\\
0 &amp; 0 &amp; 1 &amp;  ... &amp; 0\\
... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp;  ... &amp; 1\\
\end{bmatrix}\]</span></p>
<p>And in the new method I proposed, <span class="math inline">\(S\)</span> is now:
<span class="math display">\[ \begin{bmatrix}
1 &amp; \frac{h}{1!} &amp; \frac{h^2}{2!} &amp;  ... &amp; \frac{h^n}{n!}\\
0 &amp; 1 &amp; \frac{h}{1!} &amp;  ... &amp; \frac{h^{n-1}}{(n-1)!}\\
0 &amp; 0 &amp; 1 &amp;  ... &amp; \frac{h^{n-2}}{(n-2)!}\\
... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp;  ... &amp; 1\\
\end{bmatrix}\]</span></p>
<p>Converting these matrices into python is fairly easy.</p>
<pre class="python"><code>import numpy as np
import math


def euler(dims, h):
    # Start with an identity matrix
    step_matrix = np.identity(dims)
    # Add in all the h values
    for i in range(dims - 1):
        step_matrix[i, i + 1] = h
    return step_matrix


def expanded_euler(dims, h):
    step_matrix = np.zeros((dims, dims))
    for i in range(dims):
        for j in range(i, dims):
            # Is 1, and h at j-i =0, 1 respectively
            step_matrix[i, j] = h ** (j - i) / math.factorial(j - i)
    return step_matrix</code></pre>
</div>
<div id="making-a-step-simulation" class="section level1">
<h1>Making a step simulation</h1>
<p>Now that we have the stepping matrices, we can use them to iterate from an initial value. All we have to do is generate the stepping matrix for the given problem, and then for each step, we just multiple the previous step by the stepping matrix.</p>
<pre class="python"><code>def IVP(x, y, step_matrix_generator, steps=10, h=0.1):
    dims = len(y)
    step_matrix = step_matrix_generator(dims, h)
    output_dict = {x: y}

    x_n = x
    y_n = y.copy()
    i = 0
    while i &lt; steps:
        y_n = step_matrix @ y_n
        x_n += h
        output_dict[x_n] = y_n
        i += 1

    return output_dict</code></pre>
</div>
<div id="testing-and-comparing-the-methods" class="section level1">
<h1>Testing and Comparing the methods</h1>
<p>Now we can run the simulations, let’s see how good they are.
Say you throw a ball up in the air and track its vertical position. The path of the ball is described by the equation <span class="math inline">\(y&#39;&#39; = -9.8\)</span>. We can know for a fact that the solution to this equation is <span class="math inline">\(\frac{-9.8}{2}x^2+V_0x+P_0\)</span>, where <span class="math inline">\(V_0\)</span> is the initial velocity and <span class="math inline">\(P_0\)</span> is the initial position. So now lets compare the real solutions to the simulations.</p>
<pre class="python"><code># Time starts at 0
x = 0
# Start the object moving upwards with a velocity of 10
y = np.array([0, 10, -9.8])

euler_result = IVP(x, y, euler)
expanded_euler_result =IVP(x, y, expanded_euler)
true_result = {x: np.array([
                    -4.9 * x**2 + 10 * x,
                    -9.8 * x + 10,
                    -9.8
                ]) for x in np.arange(0, 1.1, 0.1)}</code></pre>
<p><img src="/post/taylor-series/post-2_files/figure-html/gravity-sim-plot-1.png" width="614" /></p>
<p>So from here, we’re looking pretty good. The new method is much closer to the true solution than the Euler method in in this scenario. However, when working with numerical methods, it generally isn’t too hard to improve the accuracy of the model, but there will be a trade off in computation time. So lets see how much longer it takes to compute the approximation with the expanded method comparing it to the original.</p>
<pre class="python"><code>import timeit

# Define the step counts to test
steps_list = [10, 100, 1000, 10000, 100000]

# Lists to store execution times for each method
euler_times = []
expanded_euler_times = []

# Testing the functions with the different step counts and store the execution times
for steps in steps_list:
    euler_time = timeit.timeit(lambda: IVP(x, y, euler, steps), number=1)
    expanded_euler_time = timeit.timeit(lambda: IVP(x, y, expanded_euler, steps), number=1)
    
    euler_times.append(euler_time)
    expanded_euler_times.append(expanded_euler_time)</code></pre>
<p><img src="/post/taylor-series/post-2_files/figure-html/time-plot-3.png" width="960" /></p>
<p>Looking at this graph, we can see that we’re not sacrificing compute time for better accuracy, so this seems like a big win, though I haven’t optimised the Euler method that much. But overall, the new method seems to show some promise in approximating differential equations.</p>
</div>
]]></content>
        </item>
        
        <item>
            <title>A new way to look at Categories in Hugo Blogs</title>
            <link>/2023/12/28/a-new-way-to-look-at-categories-in-hugo-blogs/</link>
            <pubDate>Thu, 28 Dec 2023 00:00:00 +0000</pubDate>
            
            <guid>/2023/12/28/a-new-way-to-look-at-categories-in-hugo-blogs/</guid>
            <description>This site is built through blogdown, which is a marvellous little R package that integrates Hugo sites into a R workflow. A nice thing about Hugo sites are the large number of themes available to quickly integrate with your site to change the vibe. My theme is mostly just a recolored version of the hello-friend-ng theme, using catppuccin for the colors.
My only gripe with the theme is that it uses a default list for all types of content.</description>
            <content type="html"><![CDATA[


<p>This site is built through <a href="https://bookdown.org/yihui/blogdown/">blogdown</a>, which is a marvellous little R package that integrates Hugo sites into a R workflow. A nice thing about Hugo sites are the large number of themes available to quickly integrate with your site to change the vibe. My theme is mostly just a recolored version of the <a href="https://github.com/rhazdon/hugo-theme-hello-friend-ng">hello-friend-ng</a> theme, using <a href="https://github.com/catppuccin">catppuccin</a> for the colors.</p>
<p>My only gripe with the theme is that it uses a default list for all types of content. If you want to look at all the posts, you see a list of posts; for tags, similarly, you get a list of tags.</p>
<div class="figure">
<img src="/post/tag-graph/1.png" alt="" />
<p class="caption">How the list of tags looks by default</p>
</div>
<div id="looking-at-the-edges" class="section level1">
<h1>Looking at the edges</h1>
<p>A software that I’ve always been meaning to use is <a href="https://obsidian.md/">obsidian</a> which is a note taking and organising software which uses plaintext. One of its features has always really intrigued me, is the graph view which organises all of the notes based on their connections.</p>
<div class="figure">
<img src="https://i.redd.it/49l0t8v09yr91.png" alt="" />
<p class="caption">An example of an obsidian graph (Sourced from u/jannesjy on reddit)</p>
</div>
<p>I thought it would be cool to implement something like this in my Hugo site. Something that lets you not only look at all the tags, but see how they are connected.</p>
</div>
<div id="starting-small" class="section level1">
<h1>Starting small</h1>
<p>Before making the graph view, I wanted to make something that allows you to see all the posts with two of the tags. That way, when you click on a node or an edge in the graph you can be taken through to see all the posts with the relevant tags.</p>
<p>Unfortunately the scripting language used by Hugo doesn’t have this kind of filtering built in. So I have to do it rather un-elegantly in JavaScript.</p>
<p>To make the linking easier, I added the second tag using the query string so that it can be reached just using a href link.</p>
<pre class="html"><code>{{ define &quot;main&quot; }}
&lt;main class=&quot;posts&quot;&gt;
  &lt;h1&gt;{{ .Title }}&lt;/h1&gt;

  &lt;div id=&quot;posts-container&quot;&gt;
    {{ $pages := where .Data.Pages &quot;Params.tags&quot; &quot;intersect&quot; (slice .Title) }}
    {{ $paginator := .Paginate $pages }}

    &lt;ul class=&quot;posts-list&quot;&gt;
      {{ range $paginator.Pages }}
      &lt;li class=&quot;post-item&quot; data-tags=&quot;{{  .Params.tags | jsonify }}&quot;&gt;
        &lt;a href=&quot;{{ .Permalink }}&quot; class=&quot;post-item-inner&quot;&gt;
          &lt;span class=&quot;post-title&quot;&gt;{{ .Title }}&lt;/span&gt;
          &lt;span class=&quot;post-date&quot;&gt;{{ .Date.Format &quot;January 2, 2006&quot; }}&lt;/span&gt;
        &lt;/a&gt;
      &lt;/li&gt;
      {{ end }}
    &lt;/ul&gt;

    {{ partial &quot;pagination-list.html&quot; . }}
  &lt;/div&gt;
&lt;/main&gt;

&lt;script&gt;
  document.addEventListener(&quot;DOMContentLoaded&quot;, function () {
    const urlParams = new URLSearchParams(window.location.search);
    let additionalTag = urlParams.get(&quot;tag&quot;);
    // Capitalize the first letter of each word
    function toTitleCase(str) {
      return str.replace(/\w\S*/g, function (txt) {
        return txt.charAt(0).toUpperCase() + txt.substr(1).toLowerCase();
      });
    }

    // Update the title with the capitalized query string tag if it exists
    if (additionalTag) {
      additionalTag = toTitleCase(additionalTag.replace(/-/g, &quot; &quot;));
      document.querySelector(&quot;h1&quot;).textContent += &quot; &amp; &quot; + additionalTag;
    }

    // Convert the additionalTag to lowercase and hyphenated format
    if (additionalTag) {
      additionalTag = additionalTag.toLowerCase().replace(/\s+/g, &quot;-&quot;);
      console.log(additionalTag);

      const posts = document.querySelectorAll(&quot;.post-item&quot;);

      posts.forEach((post) =&gt; {
        const tagsString = JSON.parse(post.getAttribute(&quot;data-tags&quot;));

        // Convert tag string into a lowercase, hyphenated array of tags
        const tags = tagsString.map((tag) =&gt;
          tag.trim().toLowerCase().replace(/\s+/g, &quot;-&quot;)
        );

        console.log(tags);

        // If the additional tag is not in the post&#39;s tags, hide the post.
        if (!tags.includes(additionalTag)) {
          post.style.display = &quot;none&quot;;
        }
      });
    }
  });
&lt;/script&gt;
{{ end }}</code></pre>
</div>
<div id="building-the-graph" class="section level1">
<h1>Building the graph</h1>
<p>Similar to the issue with creating the post listing page, constructing the graph requires some rather unwieldy JavaScript to make it work.</p>
<div id="fetching-all-the-posts" class="section level2">
<h2>Fetching All the Posts</h2>
<p>The first thing to do is to fetch all the posts from across the site with their tags.</p>
<pre class="javascript"><code>// Create an array to hold all posts and their details
var postsData = [];

// Iterate through each page to collect its title, permalink, and tags
{{ range .Site.RegularPages }}
  // Use &#39;jsonify&#39; to convert tags to a JSON array, if tags are not present, default to an empty array
  var tags = {{ if .Params.tags }}{{ .Params.tags }}{{ else }}[]{{ end }};
  postsData.push({
    title: {{ .Title }},
    permalink: {{ .RelPermalink }},
    tags: tags // This is now a real JavaScript array
  });
{{ end }}

// Log the posts information in the console as JSON
console.log(postsData);

var tagsToPosts = {};

// Loop through each post
postsData.forEach(function(post) {
  // Loop through each tag in the current post
  post.tags.forEach(function(tag) {
    // If the tag hasn&#39;t been added to tagsToPosts, initialize it with an empty array
    if (!tagsToPosts.hasOwnProperty(tag)) {
      tagsToPosts[tag] = [];
    }
    // Add the current post to the array for this tag
    tagsToPosts[tag].push({
      title: post.title,
      permalink: post.permalink
    });
  });
});</code></pre>
</div>
<div id="invert-the-keys-of-the-list" class="section level2">
<h2>Invert the keys of the list</h2>
<p>Now that there is a list of posts with there tags, we can now invert the list so that we have all the tags with their posts.</p>
<pre class="javascript"><code>var tagsToPosts = {};

// Loop through each post
postsData.forEach(function(post) {
  // Loop through each tag in the current post
  post.tags.forEach(function(tag) {
    // If the tag hasn&#39;t been added to tagsToPosts, initialize it with an empty array
    if (!tagsToPosts.hasOwnProperty(tag)) {
      tagsToPosts[tag] = [];
    }
    // Add the current post to the array for this tag
    tagsToPosts[tag].push({
      title: post.title,
      permalink: post.permalink
    });
  });
});
// Log the new tags to posts dictionary
console.log(tagsToPosts);</code></pre>
</div>
<div id="make-a-matrix-of-connections" class="section level2">
<h2>Make a matrix of connections</h2>
<p>With the list of tags, we can now make a matrix showing all of the connections between the tags. This is really inefficient but it works well enough that I don’t think it requires too much optimisation.</p>
<pre class="javascript"><code>// Get all unique tags
var uniqueTags = Object.keys(tagsToPosts);

// Initialize the matrix with zeros
var tagMatrix = uniqueTags.map(() =&gt; uniqueTags.map(() =&gt; 0));

// Function to check the intersection of posts for two tags
function getSharedPostsCount(tagA, tagB, tagsToPosts) {
  var postsA = tagsToPosts[tagA];
  var postsB = tagsToPosts[tagB];
  var shared = postsA.filter(postA =&gt; postsB.some(postB =&gt; postA.permalink === postB.permalink));
  return shared.length;
}

// Populate the matrix with shared post counts
for (let i = 0; i &lt; uniqueTags.length; i++) {
  for (let j = i; j &lt; uniqueTags.length; j++) {
    // We only need to calculate the upper triangular matrix due to symmetry
    var sharedCount = getSharedPostsCount(uniqueTags[i], uniqueTags[j], tagsToPosts);
    tagMatrix[i][j] = sharedCount;
    tagMatrix[j][i] = sharedCount; // The matrix is symmetric so we mirror the count
  }
}

// Log the matrix
console.log(tagMatrix);</code></pre>
</div>
<div id="build-the-graph" class="section level2">
<h2>Build the graph</h2>
<p>Building the graph was honestly one of the easiest parts of this project. The <a href="https://d3js.org/">d3js</a> library has an object called a force directed graph, has most of the features I would want baked in.</p>
<p>The only interesting thing I’ve done here is add in on-click links to the nodes and the edges that allow you to click through to see the relevant posts.</p>
<pre class="javascript"><code>var width = window.innerWidth;
var height = window.innerHeight;

// Setup the window
var svg = d3.select(&quot;body&quot;)
  .append(&quot;svg&quot;)
  .attr(&quot;width&quot;, width)
  .attr(&quot;height&quot;, height)
  .style(&quot;display&quot;, &quot;block&quot;)
  .style(&quot;margin&quot;, &quot;auto&quot;);

var nodeRadius = 60;
var collisionRadius = nodeRadius * 2;

// Setup the simulation
var simulation = d3.forceSimulation(nodes)
  .force(&quot;link&quot;, d3.forceLink(links)
    .id(d =&gt; d.id)
    .distance(200)
    .strength(d =&gt; 0.1 * d.value))
  .force(&quot;charge&quot;, d3.forceManyBody()
    .strength(d =&gt; -500 * (d.value + 1)))
  .force(&quot;center&quot;, d3.forceCenter(width / 2, height / 2))
  .force(&quot;collision&quot;, d3.forceCollide(collisionRadius))
  .alphaDecay(0.01);

// System for dragging
var dragHandler = d3.drag()
  .on(&quot;start&quot;, function(d) {
    if (!d3.event.active) simulation.alphaTarget(0.3).restart();
    d.fx = d.x;
    d.fy = d.y;
  })
  .on(&quot;drag&quot;, function(d) {
    d.fx = d3.event.x;
    d.fy = d3.event.y;
  })
  .on(&quot;end&quot;, function(d) {
    if (!d3.event.active) simulation.alphaTarget(0);
    d.fx = null;
    d.fy = null;
  });

// Draw the line between the nodes
var link = svg.append(&quot;g&quot;)
  .attr(&quot;class&quot;, &quot;links&quot;)
  .selectAll(&quot;line&quot;)
  .data(links)
  .enter().append(&quot;line&quot;)
  .attr(&quot;stroke-width&quot;, d =&gt; Math.sqrt(d.value) + 10)
  .attr(&quot;stroke&quot;, &quot;#cad3f5&quot;)
  .on(&quot;click&quot;, function(d) {
    console.log(`Link clicked between ${d.source.id} and ${d.target.id}`);
    let tagName1 = d.source.id.replace(/\s+/g, &#39;-&#39;).toLowerCase();
    let tagName2 = d.target.id.replace(/\s+/g, &#39;-&#39;).toLowerCase();
    window.location.href = `/tags/${tagName1}?tag=${tagName2}`;
  });

var colors = [
  &#39;#f4dbd6&#39;,
  &#39;#b7bdf8&#39;,
  &#39;#ed8796&#39;,
  &#39;#f5a97f&#39;,
  &#39;#eed49f&#39;,
  &#39;#a6da95&#39;,
  &#39;#8bd5ca&#39;,
  &#39;#8aadf4&#39;,
  &#39;#c6a0f6&#39;,
  &#39;#f0c6c6&#39;
];

function getRandomColor() {
  return colors[Math.floor(Math.random() * colors.length)];
}



// Make the nodes
var node = svg.append(&quot;g&quot;)
  .attr(&quot;class&quot;, &quot;nodes&quot;)
  .selectAll(&quot;circle&quot;)
  .data(nodes)
  .enter().append(&quot;circle&quot;)
  .on(&quot;click&quot;, function(d) {
    let tagName = d.id.replace(/\s+/g, &#39;-&#39;).toLowerCase();
    window.location.href = `/tags/${tagName}`;
  })
  .attr(&quot;r&quot;, nodeRadius)
  .attr(&quot;fill&quot;, function(d) { return getRandomColor(); });

node.append(&quot;title&quot;)
  .text(d =&gt; d.id);

simulation
  .nodes(nodes)
  .on(&quot;tick&quot;, ticked);

simulation.force(&quot;link&quot;)
  .links(links);

dragHandler(node);

// Wirite out the labels
var labels = svg.append(&quot;g&quot;)
  .attr(&quot;class&quot;, &quot;labels&quot;)
  .selectAll(&quot;text&quot;)
  .data(nodes)
  .enter().append(&quot;text&quot;)
  .text(d =&gt; d.id)
  .style(&quot;fill&quot;, &quot;24273a&quot;)
  .style(&quot;text-anchor&quot;, &quot;middle&quot;)
  .style(&quot;dominant-baseline&quot;, &quot;central&quot;)
  .on(&quot;click&quot;, function(d) {
    let tagName = d.id.replace(/\s+/g, &#39;-&#39;).toLowerCase();
    window.location.href = `/tags/${tagName}`;
  });

// Update function
function ticked() {
  link
    .attr(&quot;x1&quot;, d =&gt; d.source.x)
    .attr(&quot;y1&quot;, d =&gt; d.source.y)
    .attr(&quot;x2&quot;, d =&gt; d.target.x)
    .attr(&quot;y2&quot;, d =&gt; d.target.y);

  node
    .attr(&quot;cx&quot;, d =&gt; d.x)
    .attr(&quot;cy&quot;, d =&gt; d.y);

  labels
    .attr(&quot;x&quot;, d =&gt; d.x)
    .attr(&quot;y&quot;, d =&gt; d.y);
}</code></pre>
<p>If you want to check out the code for this in full, you can get the <a href="https://github.com/Fonzzy1/alfiechadwick-dot-com/blob/main/themes/hello-friend-ng/layouts/taxonomy/tag.html">post page</a> and the <a href="https://github.com/Fonzzy1/alfiechadwick-dot-com/blob/main/themes/hello-friend-ng/layouts/taxonomy/tag.terms.html">graph page</a> from github, or checkout the graph in its current state <a href="/tags/">here</a>.</p>
</div>
</div>
]]></content>
        </item>
        
        <item>
            <title>Using Taylor Series to Improve the Euler Method</title>
            <link>/2023/12/18/using-taylor-series-to-improve-the-euler-method/</link>
            <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
            
            <guid>/2023/12/18/using-taylor-series-to-improve-the-euler-method/</guid>
            <description>Euler’s Method Higher Order ODEs Taylor Series Putting it together Euler’s Method Euler’s method is a classic way of approximating first-order differential equations. In short, it uses the derivative of a function and starting condition to estimate the value of the function a short distance from the starting point.
This is commonly written as:
\[ \frac{dy}{dx} = f(x, y) \] \[ y(x+h) = y(x) + hf(x, y(x)) + \epsilon \] \[ \lim_{h \to 0} |\epsilon| = 0 \]</description>
            <content type="html"><![CDATA[

<div id="TOC">
<ul>
<li><a href="#eulers-method">Euler’s Method</a>
<ul>
<li><a href="#higher-order-odes">Higher Order ODEs</a></li>
</ul></li>
<li><a href="#taylor-series">Taylor Series</a></li>
<li><a href="#putting-it-together">Putting it together</a></li>
</ul>
</div>

<div id="eulers-method" class="section level1">
<h1>Euler’s Method</h1>
<p>Euler’s method is a classic way of approximating first-order differential equations.
In short, it uses the derivative of a function and starting condition to estimate the value of the function a short distance from the starting point.</p>
<p>This is commonly written as:</p>
<p><span class="math display">\[
\frac{dy}{dx} = f(x, y)
\]</span>
<span class="math display">\[
y(x+h) = y(x) + hf(x, y(x)) + \epsilon
\]</span>
<span class="math display">\[
\lim_{h \to 0} |\epsilon| = 0
\]</span></p>
<p>Where <span class="math inline">\(\epsilon\)</span> is the error created by the approximation.</p>
<div id="higher-order-odes" class="section level2">
<h2>Higher Order ODEs</h2>
<p>Generalizing Euler’s method to higher order ODEs is pretty easy. All you have to do is think of the ODE as a vector with each entry being the next derivative of the function. You can now write Euler’s Method in terms of this function:</p>
<p><span class="math display">\[ 
\begin{bmatrix}
y(x+h)\\
y&#39;(x+h)\\
y&#39;&#39;(x+h)\\
...\\
y^{n-1}(x+h)\\
\end{bmatrix} = \begin{bmatrix}
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n-1}(x)\\
\end{bmatrix} + \begin{bmatrix}
h &amp; 0 &amp; 0 &amp;  ... &amp; 0\\
0 &amp; h &amp; 0 &amp;  ... &amp; 0\\
0 &amp; 0 &amp; h &amp;  ... &amp; 0\\
... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp;  ... &amp; h\\
\end{bmatrix} \cdot \begin{bmatrix}
y&#39;(x)\\
y&#39;&#39;(x)\\
y&#39;&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix} + \epsilon
\]</span></p>
<p>Or shifting the <span class="math inline">\(Y&#39;\)</span> matrix to make it a bit prettier:</p>
<p><span class="math display">\[\begin{bmatrix}
y(x+h)\\
y&#39;(x+h)\\
y&#39;&#39;(x+h)\\
...\\
y^{n}(x+h)\\
\end{bmatrix} =  \begin{bmatrix}
1 &amp; h &amp; 0 &amp;  ... &amp; 0\\
0 &amp; 1 &amp; h &amp;  ... &amp; 0\\
0 &amp; 0 &amp; 1 &amp;  ... &amp; 0\\
... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp;  ... &amp; 1\\
\end{bmatrix} \cdot \begin{bmatrix}
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix} + \epsilon \]</span></p>
</div>
</div>
<div id="taylor-series" class="section level1">
<h1>Taylor Series</h1>
<p>So everything up to now has been pretty textbook. But when I saw the matrix representation of the Euler method, I couldn’t help but think of another method that combines derivatives and linear algebra, Taylor Series.
Taylor Series allows you to express functions as a polynomial of their derivatives at a single point <span class="math inline">\(a\)</span>, as defined by this equation:</p>
<p><span class="math display">\[
y(x) =  \sum_{n = 0}^{\infty}  \frac{y^{(n)}(a)}{n!}\cdot(x - a)^n 
\]</span></p>
<p>The link between the Taylor Series and Euler’s Method becomes clear when we replace <span class="math inline">\(x\)</span> with <span class="math inline">\(x+h\)</span> and <span class="math inline">\(a\)</span> with <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
y(x+h) =  \sum_{n = 0}^{\infty}  \frac{y^{(n)}(x)}{n!}\cdot(h)^n 
\]</span></p>
<p><span class="math display">\[
y(x+h) = y(x) +  y&#39;(x) \cdot h + \frac{y&#39;&#39;(x)}{2!}\cdot(h)^2 + \frac{y&#39;&#39;&#39;(x)}{3!}\cdot(h)^3 ...
\]</span></p>
<p>The first two terms of this expansion are the same as Euler’s Method, but the additional terms provide even greater accuracy, minimizing the error in the approximation!</p>
</div>
<div id="putting-it-together" class="section level1">
<h1>Putting it together</h1>
<p>A nice property of Taylor Series is that they have a really simple derivative function:</p>
<p><span class="math display">\[ y&#39;(a+h) = \sum_{n = 0}^{\infty}  \frac{y^{(n+1)}(a)}{n!}\cdot(h)^n \]</span>
<span class="math display">\[ y^{(m)}(a+h) = \sum_{n = 0}^{\infty}  \frac{y^{(n+m)}(a)}{n!}\cdot(h)^n \]</span></p>
<p>This means that not only the function can be described as a linear combination of the derivatives at a point, but so too can all derivatives of a function.</p>
<p>Using this, we can go back to the initial matrix representation of the Euler method and include these higher order terms.</p>
<p><span class="math display">\[ \begin{bmatrix}
y(x+h)\\
y&#39;(x+h)\\
y&#39;&#39;(x+h)\\
...\\
y^{n}(x+h)\\
\end{bmatrix} = \begin{bmatrix}
1 &amp; \frac{h}{1!} &amp; \frac{h^2}{2!} &amp;  ... &amp; \frac{h^n}{n!}\\
0 &amp; 1 &amp; \frac{h}{1!} &amp;  ... &amp; \frac{h^{n-1}}{(n-1)!}\\
0 &amp; 0 &amp; 1 &amp;  ... &amp; \frac{h^{n-2}}{(n-2)!}\\
... &amp; ... &amp; ... &amp;  ... &amp; ...\\
0 &amp; 0 &amp; 0 &amp;  ... &amp; 1\\
\end{bmatrix} \cdot \begin{bmatrix}
y(x)\\
y&#39;(x)\\
y&#39;&#39;(x)\\
...\\
y^{n}(x)\\
\end{bmatrix} + \epsilon \]</span></p>
<p>This should allow us to approximate higher order ODEs with more precision than just using Euler’s method.</p>
</div>
]]></content>
        </item>
        
        <item>
            <title>Modeling Drug Use in Communities</title>
            <link>/2023/10/22/modeling-drug-use-in-communities/</link>
            <pubDate>Sun, 22 Oct 2023 00:00:00 +0000</pubDate>
            
            <guid>/2023/10/22/modeling-drug-use-in-communities/</guid>
            <description>Preface Introduction Aim Method Initial Model: SIR SUAR Model SAUR Model with age Simplified SUAR Model with age Results Discussion Conclusion References Appendix Appendix 1 : Stationary points of SIR model Appendix 2 : Stationary points of SUAR Appendix 3: Critical Points of Simplified SUAR model Appendix 4: Matlab code for generating conditional Stationary Points Appendix 5: Python code for simulating SIR model Appendix 6: Python code for simulating SUAR model Appendix 7: Python code for simulating 20 compartment SUAR model Appendix 8: Python code for simulating 5 compartment SUAR model Appendix 9: Python code for simulating 5 compartment dimensionless SUAR model Preface This was written as a University project but I’m pretty happy with how it turned out.</description>
            <content type="html"><![CDATA[

<div id="TOC">
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#aim">Aim</a></li>
<li><a href="#method">Method</a>
<ul>
<li><a href="#initial-model-sir">Initial Model: SIR</a></li>
<li><a href="#suar-model">SUAR Model</a></li>
<li><a href="#saur-model-with-age">SAUR Model with age</a></li>
<li><a href="#simplified-suar-model-with-age">Simplified SUAR Model with age</a></li>
</ul></li>
<li><a href="#results">Results</a></li>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
<li><a href="#appendix">Appendix</a>
<ul>
<li><a href="#appendix-1-stationary-points-of-sir-model">Appendix 1 : Stationary points of SIR model</a></li>
<li><a href="#appendix-2-stationary-points-of-suar">Appendix 2 : Stationary points of SUAR</a></li>
<li><a href="#appendix-3-critical-points-of-simplified-suar-model">Appendix 3: Critical Points of Simplified SUAR model</a></li>
<li><a href="#appendix-4-matlab-code-for-generating-conditional-stationary-points">Appendix 4: Matlab code for generating conditional Stationary Points</a></li>
<li><a href="#appendix-5-python-code-for-simulating-sir-model">Appendix 5: Python code for simulating SIR model</a></li>
<li><a href="#appendix-6-python-code-for-simulating-suar-model">Appendix 6: Python code for simulating SUAR model</a></li>
<li><a href="#appendix-7-python-code-for-simulating-20-compartment-suar-model">Appendix 7: Python code for simulating 20 compartment SUAR model</a></li>
<li><a href="#appendix-8-python-code-for-simulating-5-compartment-suar-model">Appendix 8: Python code for simulating 5 compartment SUAR model</a></li>
<li><a href="#appendix-9-python-code-for-simulating-5-compartment-dimensionless-suar-model">Appendix 9: Python code for simulating 5 compartment dimensionless SUAR model</a></li>
</ul></li>
</ul>
</div>

<div id="preface" class="section level1">
<h1>Preface</h1>
<p>This was written as a University project but I’m pretty happy with how it turned out.</p>
<p>Big thanks to Kevin Dai and Chrysovalantis Thomopoulos who worked with me on this throughout the semester.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Drugs are chemical substances with physiological effects. Some drugs like opioids, cannabis, alcohol, nicotine, cocaine, methamphetamine, or heroin are of concern to policymakers. Widespread drug abuse in a community can be a burden to society and the economy. For example, healthcare costs increase due to bodily harm, there is an enhanced risk of infectious diseases through second-hand needle injections, indirect funding of organized crime occurs, and there are negative impacts on mental health and rehabilitation. Further harms of drug abuse upon the abuser may include financial instability, death, and familial grief.</p>
<p>“Number one is the opioid epidemic. It is a scourge across our country. A person dies every 12-and-a-half minutes from an opioid overdose and that’s far too many. Especially when we know that many of those deaths can be prevented.” (Thedoctors.com, 2021)</p>
<p>These were the words of Dr. Adams, the 20th surgeon general of the United States when asked about his main concerns and focus indicating the severity of the matter. Substance abuse is not only harmful for oneself but our community. Multiple research articles and papers in the past have modeled drug use. We have included some examples below from which we have taken inspiration and made comparisons.</p>
<p>One article in particular by Mushanyu, J, Nyabadza, F, Muchatibaya, G, &amp; Stewart, A G. R. (2016) touches on the importance of an adequate healthcare system since a limited rehabilitation capacity can increase the chances of a drug abuse epidemic. The methods used in this paper are discussed later. Also, Mushanyu, J, Nyabadza, F, &amp; Stewart, A G R. (2015) focuses on some matters that are of great importance as well.</p>
<p>Having an understanding of the dynamics of drug use will inform decision makers’ strategies to minimize drug use. In this paper, we aim to understand how drug use and addiction develop in a community and what factors can be tweaked to alter the long-term distributions of drug use, abuse, and addiction in the community.</p>
</div>
<div id="aim" class="section level1">
<h1>Aim</h1>
<p>The aim of this project is to produce a model to capture the dynamics of drug use in the long term. The model should address how or when individuals become drug users, addicted drug users, and abstainers, and have applications in addressing economic and policy decisions.</p>
</div>
<div id="method" class="section level1">
<h1>Method</h1>
<div id="initial-model-sir" class="section level2">
<h2>Initial Model: SIR</h2>
<p>It’s common to liken drug use to disease, treating drug addiction as an infection that can be recovered from. Using this analogy, we began looking into how diseases are modeled and how we can adapt our own model to fit drug usage.
One of the simplest drug models is the SIR model, a compartment model based on the concept of mass action that sees infections as caused by interactions between infected people and susceptible people. The use of mass action can be justified in this case as we are looking at large populations over a long period of time, meaning that the variance in the movement will average out over time.
There are a few reasons that this model is a good starting point for any type of drug modeling:
Firstly, this model is very simple and can be easily adapted to our own needs with extra compartments and transferable conditions.
Secondly, since we are looking at drug use in a population, relying on mass action rather than discrete modeling allows us to further simplify the model.
Thirdly, the idea that addiction is caused by interactions between individuals seems to be a good assumption for drug use as one would expect people to become familiar and subsequently addicted to certain substances by being associated with people who have them.</p>
<p>One divergence we made from the most basic SIR model is allowing for relapse from the recovered group back into the infected group. This represents how recovering addicts will become addicted again at a different rate than people who have never used the drug before. However, an important fact is that people cannot move back into the susceptible group as addiction is said to last a lifetime.</p>
<div class="figure">
<img src="/post/drug-use-models/pics/1.png" alt="" />
<p class="caption">SIR Diagram</p>
</div>
<p>Our SIR model is defined by the following equations:
<span class="math display">\[\frac{dS}{dt} = -\pi_1 * S * I \]</span>
<span class="math display">\[\frac{dI}{dt} = \pi_1 * S * I + \pi_2 * R * I - \pi_3 *  I \]</span>
<span class="math display">\[\frac{dR}{dt} = -\pi_2 * R * I + \pi_3 * I \]</span></p>
<p>The parameters <span class="math inline">\(\pi_1\)</span>, <span class="math inline">\(\pi_2\)</span>, and <span class="math inline">\(\pi_3\)</span> represent the ‘infectiousness’ of the drug for susceptible and recovering individuals and the rate of recovery from the drug, respectively.</p>
<p>We now look at some plots to see how this model behaves for various combinations of our parameters:</p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/SIRsims-1.png" width="960" /></p>
</div>
<div id="suar-model" class="section level2">
<h2>SUAR Model</h2>
<p>The SIR model fails to distinguish between different severities of addiction. By grouping the individuals who are trying/testing the drug with people who are addicted, we fail to capture the behavior of people trying the drug without becoming reliant on it.
Because of this, we adapted the SIR model, relabeled the infected group to addicted, and added in a new compartment model for users of the drug who are not addicted, the ‘using’ group. Susceptible people will now move into the using group before moving into the Addicted group. Since there are now two groups who are using the drug and interacting with the community, the <span class="math inline">\(I\)</span> terms of the ODEs in the SIR model have to be replaced with <span class="math inline">\(U+A\)</span>.</p>
<div class="figure">
<img src="/post/drug-use-models/pics/2.png" alt="" />
<p class="caption">SUAR Diagram</p>
</div>
<p>The new model can now be described by the following equations:</p>
<p><span class="math display">\[\frac{dS}{dt} = - \pi_1*S*(A+U) + \pi_2*U   \]</span>
<span class="math display">\[\frac{dU}{dt} =  \pi_1*S*(A+U) - \pi_2*U  - \pi_3*U \]</span>
<span class="math display">\[\frac{dA}{dt} = \pi_3*U +\pi_5 *(A+U)*R - \pi_4*A \]</span>
<span class="math display">\[\frac{dR}{dt} =  \pi_4*A - \pi_5 *(A+U)*R \]</span></p>
<p>With parameters <span class="math inline">\(\pi_1\)</span>, <span class="math inline">\(\pi_2\)</span>, <span class="math inline">\(\pi_3\)</span>, <span class="math inline">\(\pi_4\)</span>, and <span class="math inline">\(\pi_5\)</span> being the ‘effectiveness’ of the drug for susceptible people, the rate that people stop trying the drug, the rate at which people become addicted, the recovery rate for addicted people respectively, and the ‘effectiveness’ for recovered people.</p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/SUARsims-3.png" width="1152" /></p>
</div>
<div id="saur-model-with-age" class="section level2">
<h2>SAUR Model with age</h2>
<p>Now focusing on the stationary points of the previous two models (see appendix for derivation), we realize that our long-term behavior involves the extinction of either the user and/or the addicted group. However, this behavior is unrealistic and rather too optimistic since there is a consistent number of people using and addicted to the drug, and a consistently high number of people who are susceptible to the drug. To fix this issue, we integrate age groups into the model, grouping the population into children, teens, young adults, adults, and seniors. Each of these groups has a distinct rate of death, and the births are proportional to the number of young adults and adults. Separating the population also allows us to set different parameters according to each age group, capturing more nuanced behaviors such as an increased volume of experimentation of young people which would not have been identified otherwise.</p>
<p>Another feature we wanted to tackle is how people recover. In the same way that people start using drugs based on interactions with others who are using them, we expect people to recover based on interactions with people who aren’t using them. This can be represented by support groups, concerned parents, friends, etc. Furthermore, we can expect people in one age group and compartment model to be influenced differently from each age group and subsequent compartment model. We can store this information with a matrix <span class="math inline">\(I\)</span>, where <span class="math inline">\(I_{ij}\)</span> is the magnitude of the influence that group j has on group i.</p>
<p>We can now go in to further simplify this by defining two new terms, the positive and negative influence on a age group <span class="math inline">\(i\)</span>, to be:
<span class="math display">\[P_i = \sum{k=1}{5}{I_{ik} * (S_k + R_K)}\]</span>
<span class="math display">\[N_i = \sum{k=1}{5}{I_{ik} * (U_k + A_K)}\]</span></p>
<p>The model now has 20 compartments with both sideways movement from and to age groups and downwards movement as people age.</p>
<p>Looking across age group ‘i’, the model can be described as:</p>
<p><span class="math display">\[\frac{dS_i}{dt} = aS_{i-1} + aU_{i-1} \pi_{i-1,2}P_{i-1} - S_i\pi_{i,1}N_i + (1-a)U_i\pi_{i,2}P_i - aSi - d_{i,s}S_i + (b\sum_{k=2}^{3}S_k+U_k+A_k+R_K | i = 0)  \]</span>
<span class="math display">\[\frac{dU_i}{dt} =  aS_{i-1}\pi_{i-1,1}N_{i-1} + aU_{i-1} - U_i * \pi_{i,3} - a U_i - U_i\pi_{i,2}P_i + (1-a)S_i\pi_{i,1}N_i - d_{i,U}U_i\]</span>
<span class="math display">\[\frac{dA_i}{dt} = aU_{i-1}\pi_{i-1,3} + aA_{i-1} + aR_{i-1}\pi_{i-1,5}N_{i-1} - A_i\pi_{i,4}P_i + (1-a)R_i\pi_{i,5}N_{i}-aA_i + (1-a)U_i\pi_{i,3}- d_{i,A}A_i\]</span>
<span class="math display">\[\frac{dR_i}{dt} = aA_{i-1}\pi_{i-1,4}P_{i-1} + aR_{i-1} - aR_i -R_i\pi_{i,5}N_i + (1-a)A_i\pi_{i,4}P_i - d_{i,R}R_I \]</span></p>
<p>With the parameters being sorted in matrices <span class="math inline">\(\pi\)</span>, {d} and {i}, containing row-wise versions of the parameters for the SAUR model, the death rate for each compartment, and the influence that each age group has on the other, and scalars <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, which define the aging rate and the birth rate of the population.</p>
</div>
<div id="simplified-suar-model-with-age" class="section level2">
<h2>Simplified SUAR Model with age</h2>
<p>After creating the SAUR model with age groups, we experimented with various combinations of parameters to see how the model reacted.
However, we found that with 20 compartments and 73 parameters, it is really hard to go through all the combinations to find meaningful results from the model. We could see that there were stationary points for the population portions, but finding them analytically was near impossible. Because of this, we sought to find a way to simplify the model to produce results that are easier to understand. We did this by removing the different age groups altogether, while keeping the equations describing the model the same. By removing the age groups, the equations dramatically simplify into this form;</p>
<div class="figure">
<img src="/post/drug-use-models/pics/3.png" alt="" />
<p class="caption">SUAR Diagram with ageing</p>
</div>
<p><span class="math display">\[\frac{dS}{dt} = -S\pi_{1}N +U\pi_2P  -d_SS + b(S+U+A+R)  \]</span>
<span class="math display">\[\frac{dU}{dt} = S\pi_1N -U\pi_2P - U\pi_3 - d_UU  \]</span>
<span class="math display">\[\frac{dA}{dt} = U\pi_3 - A\pi_4P + R\pi_5N - d_AA\]</span>
<span class="math display">\[\frac{dR}{dt} = A\pi_4P - R\pi_5N - d_RR \]</span></p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/SUAR_5Sims-5.png" width="1152" /></p>
<p>Looking at this model, it is clear to see that we will only find stationary points when births and deaths are equal. However we also want to see long term trends in growing and shrinking populations. To do this, we look at this model through population portions, redefining the system as:</p>
<p><span class="math display">\[ T = S + U + A + R \]</span>
<span class="math display">\[ T&#39; = b(S+U+A+R)  -d_SS -d_UU - d_AA - d_RR \]</span></p>
<p><span class="math display">\[ \frac{d\frac{S}{N}}{dt} = \frac{(-S\pi_{1}N +U\pi_2P  -d_SS + b(S+U+A+R))T-T&#39;S}{T^2} \]</span>
<span class="math display">\[ \frac{d\frac{U}{N}}{dt} = \frac{(S\pi_1N -U\pi_2P - U\pi_3 - d_UU )T-T&#39;U}{T^2} \]</span>
<span class="math display">\[ \frac{d\frac{A}{N}}{dt} = \frac{(U\pi_3 - A\pi_4P + R\pi_5N - d_AA)T-T&#39;A}{T^2}  \]</span>
<span class="math display">\[ \frac{d\frac{R}{N}}{dt} = \frac{(A\pi_4P - R\pi_5N - d_RR )T-T&#39;R}{T^2} \]</span></p>
<p>Denoting these fractions as s,u,a,r and reformatting the equation using T as a characteristic for population and <span class="math inline">\(\frac{1}{b}\)</span> as a characteristic for time;</p>
<p><span class="math display">\[ s+u+a+r = 1\]</span>
<span class="math display">\[ \frac{ds}{dt} = (-s\pi_{1}(u+a)+u\pi_2(s+r)  -d_Ss + 1)-s(1 - d_Ss - d_Uu - d_Aa - d_Rr) \]</span>
<span class="math display">\[ \frac{du}{dt} = (s\pi_{1}(u+a)-u\pi_2(s+r) - u\pi_3 -d_Uu )-u(1 - d_Ss - d_Uu - d_Aa - d_Rr) \]</span>
<span class="math display">\[ \frac{da}{dt} = (u\pi_3 -a\pi_4(s+r) + r\pi_5(u+a) -d_Aa )-a(1 - d_Ss - d_Uu - d_Aa - d_Rr)  \]</span>
<span class="math display">\[ \frac{dr}{dt} = (a\pi_4(s+r) - r\pi_5(u+a) -d_Rr )-r(1 - d_Ss - d_Uu - d_Aa - d_Rr)\]</span></p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/SUARnormsims-7.png" width="1152" /></p>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>We can think of deaths as a movement from all compartments to the susceptible compartments. This makes it clear that a stationary point exists when all the people are in the susceptible compartment, meaning the drug is ‘extinct’. Similarly, the drug is also extinct when everyone is either in the recovered or susceptible group, as one just has to wait for the recovered people to die for the portion of S to reach 1. These two facts can be seen in appendix 3. Let the stationary point at <span class="math inline">\(s=1\)</span> be the trivial stationary point.</p>
<p>However, for some combinations of parameters, secondary stationary points are found. These non-trivial stationary points could not be found analytically using MATLAB 2021b, therefore their existence must be verified on a case-by-case basis, using the code in appendix 4.
Note that all the death parameters were set to one, meaning that these results are for drugs where the rate of death is independent of the compartment. To find results for other sets of death parameters, line 25 of appendix 4 should be altered.</p>
<p>Using the table of non-trivial stationary points (appendix 10), we can now plot the number of combinations of parameters that lead to non-trivial stationary points pairwise by parameter.</p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/simforallparams-9.png" width="672" /></p>
<p>From this plot, one can see a big factor that influences the creation of these non-trivial stationary points is the magnitude of <span class="math inline">\(\pi_1\)</span>, and to a lesser extent the ratio of <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(\pi_2\)</span>. In this case, births will rapidly transition to the using category, meaning that they then have the potential to become addicted.</p>
<p>Another result one can take from the data is the number of people who are using or addicted to the drug at the pseudo-stationary points, as shown in the plots below.</p>
<p><img src="/post/drug-use-models/final_report_files/figure-html/pssp-11.png" width="672" />
Looking at these plots we can see the following behaviors:</p>
<ul>
<li>Bigger <span class="math inline">\(\pi_1\)</span> <span class="math inline">\(\to\)</span> Higher Mean</li>
<li>Bigger <span class="math inline">\(\pi_2\)</span> <span class="math inline">\(\to\)</span> Lower Mean</li>
<li>Bigger <span class="math inline">\(\pi_3\)</span> <span class="math inline">\(\to\)</span> Lower Mean</li>
<li>Bigger <span class="math inline">\(\pi_4\)</span> <span class="math inline">\(\to\)</span> Lower Mean</li>
<li>Bigger <span class="math inline">\(\pi_5\)</span> <span class="math inline">\(\to\)</span> Higher Mean</li>
</ul>
<p>Therefore, in terms of the long-term state of drug use in communities, the best way to minimize drug use is to minimize <span class="math inline">\(\pi_1\)</span> such that the drug becomes extinct. If this cannot be done, the number of people using or addicted to drugs can be minimized by lowering the values of <span class="math inline">\(\pi_2, \pi_3, \pi_4\)</span> or maximizing the value of <span class="math inline">\(\pi_5\)</span> to make the stationary point have a minimal number of people using the drug.</p>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>Contrasting the simplified SUAR model with Nyabadza et al (2016) on crystal meth use in South Africa, the forcing parameter for a susceptible individual to transfer out of their compartment was a weighted sum of U and A rather than the sum scaled, furthermore, there was a forcing parameter dependent on the size of the drug supply chain.</p>
<p>Another downside of our model is the fact that we have not focused on one specific substance and rather decided to adopt a more general approach to the problem. When focusing on one substance and/or a “family” of substances such as in the paper by Mushanyu, J, Nyabadza, F, &amp; Stewart, A G R. (2015) we can narrow down our results and get more specific and detailed answers.</p>
<p>A question posed by the model is how we arrive at the various states that we see at t = 0.
For non-illicit drugs like cigarettes and alcohol, marketing strategies from distributors like television ads, billboards etc. can persuade susceptible members to initiate. We suggest the forcing parameter to be a function of the industry’s market cap. Australia has plain packaging laws to dampen the forcing parameter. For illicit drugs, the supply of the drug depends on network effects. Online drug markets like The Silk Road can be assumed to have no interaction with non-users. Its only effect is to the accessibility of drugs for people in compartments U and A. Adding in forcing functions into the model, and/or allowing the parameters to change as a function of time will allow for these events to be modeled.</p>
<p>Regarding the findings of the model, the way parameters are altered to change when the trivial stationary point is found, or the level of drug use in a nontrivial stationary point seem in line with common policies targeting drug minimization. By lowering the amount of people who start using the drug, such as Australia’s ban on cigarette marketing. More generally, the results show that the best way to reduce drug use is to minimize the net movement from susceptible to using and recovered to addicted.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The aim of this project was to model the long-term outcomes of drug use in a community.
Four models were developed: the initial SIR model, a modified SUAR model, the SUAR model with age-structure, then the simplified SUAR model with age.
For the closed population models, the simulations had one of two outcomes: no drug users or entirely drug users. When births and deaths are accounted for, the population can have endemic proportions of susceptible, using, addicted, and recovered members.
We found ways to push drug use to extinction by manipulating the transmission parameters.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ol style="list-style-type: decimal">
<li>Mushanyu, J, Nyabadza, F, Muchatibaya, G, &amp; Stewart, A G. R. (2016). Modelling Drug Abuse Epidemics in the Presence of Limited Rehabilitation Capacity. Bulletin of Mathematical Biology, 78(12), 2364-2389. <a href="https://doi.org/10.1007/s11538-016-0218-5" class="uri">https://doi.org/10.1007/s11538-016-0218-5</a></li>
<li>Mushanyu, J, Nyabadza, F, &amp; Stewart, A G R. (2015). Modelling the trends of inpatient and outpatient rehabilitation for methamphetamine in the Western Cape province of South Africa. BMC Research Notes, 8(796), 797-797. <a href="https://doi.org/10.1186/s13104-015-1741-4" class="uri">https://doi.org/10.1186/s13104-015-1741-4</a></li>
<li>Betterhealth.vic.gov.au. 2021. Drug use in Victoria - Better Health Channel. [online] Available at: <a href="https://www.betterhealth.vic.gov.au/health/healthyliving/drug-use-in-victoria" class="uri">https://www.betterhealth.vic.gov.au/health/healthyliving/drug-use-in-victoria</a> [Accessed 21 October 2021].</li>
<li>Thedoctors.com. 2021. U.S. Surgeon General Discusses the Opioid Epidemic. [online] Available at: <a href="https://www.thedoctors.com/articles/u.s.-surgeon-general-discusses-the-opioid-epidemic/" class="uri">https://www.thedoctors.com/articles/u.s.-surgeon-general-discusses-the-opioid-epidemic/</a> [Accessed 21 October 2021].</li>
<li>Caulkins, Jonathan P, Dietze, Paul, &amp; Ritter, Alison. (2007). Dynamic compartmental model of trends in Australian drug use. Health Care Management Science, 10(2), 151-162. <a href="https://doi.org/10.1007/s10729-007-9012-0" class="uri">https://doi.org/10.1007/s10729-007-9012-0</a></li>
<li>Harvim, P., Zhang, H., Georgescu, P., &amp; Zhang, L. (2021). Cigarette smoking on college campuses: An epidemical modelling approach. Journal of Applied Mathematics and Computing, 65(1), 515-540. <a href="https://doi.org/10.1007/s12190-020-01402-y" class="uri">https://doi.org/10.1007/s12190-020-01402-y</a></li>
<li>Nyabadza, F., Njagarah, J. B. H., &amp; Smith, R. J. (2013). Modelling the Dynamics of Crystal Meth (‘Tik’) Abuse in the Presence of Drug-Supply Chains in South Africa. Bulletin of Mathematical Biology, 75(1), 24-48. <a href="https://doi.org/10.1007/s11538-012-9790-5" class="uri">https://doi.org/10.1007/s11538-012-9790-5</a></li>
</ol>
<div style="page-break-after: always;"></div>
</div>
<div id="appendix" class="section level1">
<h1>Appendix</h1>
<div id="appendix-1-stationary-points-of-sir-model" class="section level2">
<h2>Appendix 1 : Stationary points of SIR model</h2>
<p><span class="math display">\[0 = -\pi_1 * S * I \]</span>
<span class="math display">\[0 = \pi_1 * S * I + \pi_2 * R * I - \pi_3 *  I \]</span>
<span class="math display">\[0 = -\pi_2 * R * I + \pi_3 * I \]</span></p>
<p>Therefore either <span class="math inline">\(\pi_1\)</span>, <span class="math inline">\(S\)</span> or <span class="math inline">\(I\)</span> must be 0</p>
<p>If <span class="math inline">\(I = 0\)</span>:</p>
<p><span class="math display">\[0 = -\pi_1 * S * 0 \]</span>
<span class="math display">\[0 = \pi_1 * S * 0 + \pi_2 * R * 0 - \pi_3 *  0 \]</span>
<span class="math display">\[0 = -\pi_2 * R * 0 + \pi_3 * 0 \]</span></p>
<p>Therefore any point [<span class="math inline">\(S\)</span>,0,<span class="math inline">\(R\)</span>] is stationary.</p>
<p>If <span class="math inline">\(\pi_1 = 0\)</span> or <span class="math inline">\(S=0\)</span>:</p>
<p><span class="math display">\[0 =  0 * I \]</span>
<span class="math display">\[0 = 0 * I + \pi_2 * R * I - \pi_3 *  I \]</span>
<span class="math display">\[0 = -\pi_2 * R * I + \pi_3 * I \]</span></p>
<p>Therefore:</p>
<p><span class="math display">\[ \pi_2 * R * I - \pi_3 *  I = - \pi_2 * R * I + \pi_3 *  I  \]</span>
<span class="math display">\[ \pi_2 * R * I = \pi_3 * I \]</span>
<span class="math display">\[ R:I = \pi_3:\pi_2 \]</span></p>
<p>Therefore any point [0, <span class="math inline">\(\frac {P_{total}*\pi_2}{\pi_2 + \pi_3}\)</span> ,<span class="math inline">\(\frac {P_{total}*\pi_3}{\pi_2 + \pi_3}\)</span>]</p>
</div>
<div id="appendix-2-stationary-points-of-suar" class="section level2">
<h2>Appendix 2 : Stationary points of SUAR</h2>
<p><span class="math display">\[0 = - \pi_1*S*(A+U) + \pi_2*U   \]</span>
<span class="math display">\[0 =  \pi_1*S*(A+U) - \pi_2*U  - \pi_3*U \]</span>
<span class="math display">\[0 = \pi_3*U +\pi_4 *(A+U)*R - \pi_5*A \]</span>
<span class="math display">\[0 =  \pi_5*A - \pi_4 *(A+U)*R \]</span></p>
<p>By combing the first two and last two equations, one can see that if the parameters are non 0, <span class="math inline">\(U=0\)</span>. Therefore:</p>
<p><span class="math display">\[ 0 = \pi_1*S*A \]</span>
<span class="math display">\[0 = \pi_4 *A*R - \pi_5*A \]</span>
<span class="math display">\[0 =  \pi_5*A - \pi_4 *A*R \]</span></p>
<p>Therefore <span class="math inline">\(S = 0\)</span> or <span class="math inline">\(A = 0\)</span>
In the case <span class="math inline">\(A = 0\)</span>, any point [<span class="math inline">\(S\)</span>,0,0,<span class="math inline">\(R\)</span>] will be stationary</p>
<p>In the case <span class="math inline">\(S=0\)</span>
<span class="math display">\[ \pi_4*A*R = \pi_5*A\]</span>
<span class="math display">\[R:A = \pi_5:\pi_4\]</span></p>
<p>Therefore any point [0,0, <span class="math inline">\(\frac {P_{total}*\pi_4}{\pi_4 + \pi_5}\)</span> ,<span class="math inline">\(\frac {P_{total}*\pi_5}{\pi_4 + \pi_5}\)</span>]</p>
</div>
<div id="appendix-3-critical-points-of-simplified-suar-model" class="section level2">
<h2>Appendix 3: Critical Points of Simplified SUAR model</h2>
<p>When s = 1:
<span class="math display">\[ s = 1\]</span>
<span class="math display">\[ \frac{ds}{dt} = (-d_Ss + 1)-s(1 - d_Ss) = (1-S)(1-d_Ss)  = 0 \]</span>
<span class="math display">\[ \frac{du}{dt} = 0 \]</span>
<span class="math display">\[ \frac{da}{dt} = 0  \]</span>
<span class="math display">\[ \frac{dr}{dt} = 0  \]</span></p>
<p>When s+r = 1:
<span class="math display">\[ s+r = 1\]</span>
<span class="math display">\[ s = 1 - r \]</span></p>
<p><span class="math display">\[ \frac{ds}{dt} = (-d_Ss + b)-s(1 - d_Ss - d_Rr)  = (1 -s)*(1 + d_r*s - d_s*s)\]</span>
<span class="math display">\[ \frac{du}{dt} = 0 \]</span>
<span class="math display">\[ \frac{da}{dt} = 0  \]</span>
<span class="math display">\[ \frac{dr}{dt} = (-d_Rr )-r(1 - d_Ss - d_Rr) = (s - 1)*(1 + d_r*s - d_s*s)\]</span></p>
</div>
<div id="appendix-4-matlab-code-for-generating-conditional-stationary-points" class="section level2">
<h2>Appendix 4: Matlab code for generating conditional Stationary Points</h2>
<pre class="octave"><code>syms s u a r p1 p2 p3 p4 p5 ds du da dr


ode1 =  (-s*p1*(u+a)+u*p2*(s+r)  -ds*s + 1)-s *(1 - ds*s - du*u - da*a - dr*r);
ode2 =  (s*p1*(u+a)-u*p2*(s+r) - u*p3 -du*u )-u*(1 - ds*s - du*u - da*a - dr*r) ;
ode3 =  (u*p3 -a*p4*(s+r) + r*p5*(u+a) -da*a )-a*(1 - ds*s - du*u - da*a - dr*r);
ode4 =  (a*p4*(s+r) - r*p5*(u+a) -dr*r )-r*(1 - ds*s -du*u - da*a - dr*r);
sums = s+u+a+r;



odes = [ode1 == 0, ode2 == 0, ode3 == 0 , ode4 == 0, sums  == 1, s&gt;=0, u &gt;= 0, a &gt;=0, r&gt;=0];


ss = [];
avg = [];

k = 3;

for p1i = -k:k
for p2i   = -k:k
for p3i  = -k:k
for p4i  = -k:k
for p5i = -k:k
[p1, p2, p3, p4, p5, ds, du, da, dr] = deal(2^p1i, 2^p2i, 2^p3i, 2^p4i, 2^p5i,1,1,1,1);
sol = solve(subs(odes),&#39;Real&#39;,true);
ss = [ss ; [p1i,p2i,p3i,p4i,p5i,length(sol.s) - 1]];
if length(sol.s) &gt; 1
avg = [avg ; [p1i,p2i,p3i,p4i,p5i,mean(sol.u(2:length(sol.u)) + sol.a(2:length(sol.a)))]];
end;end;end;end;end;end



writematrix(double(avg),&#39;avg.csv&#39;)
writematrix(double(ss), &#39;ss.csv&#39;)</code></pre>
</div>
<div id="appendix-5-python-code-for-simulating-sir-model" class="section level2">
<h2>Appendix 5: Python code for simulating SIR model</h2>
<pre><code>## def SIR(p1, p2, p3, S0, I0, R0, i):
##     vect_initial = np.array([S0, I0, R0]).T
## 
##     output = pd.DataFrame(columns=[&quot;day&quot;, &quot;S&quot;, &quot;I&quot;, &quot;R&quot;])
##     j = 0
##     vect = vect_initial.copy()
## 
##     while j &lt; i:
##         vectplus1 = np.zeros([3])
##         S = vect[0]
##         I = vect[1]
##         R = vect[2]
##         vectplus1[0] = S - p1 * S * I
##         vectplus1[1] = I + p1 * S * I + p2 * R * I - p3 * I
##         vectplus1[2] = R - p2 * R * I + p3 * I
##         output.loc[j] = np.concatenate((np.array([j]), vectplus1.T))
##         vect = vectplus1.copy()
##         j += 1
## 
##     plt.plot(output[&quot;day&quot;], output[&quot;S&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;I&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;R&quot;])
##     plt.title(&quot;p1=&quot; + str(p1) + &quot;, p2=&quot; + str(p2) + &quot;, p3=&quot; + str(p3))
##     plt.legend([&quot;S&quot;, &quot;I&quot;, &quot;R&quot;])</code></pre>
</div>
<div id="appendix-6-python-code-for-simulating-suar-model" class="section level2">
<h2>Appendix 6: Python code for simulating SUAR model</h2>
<pre><code>## def SUAR(p1, p2, p3, p4, p5, S0, U0, A0, R0, i):
##     vect_initial = np.array([S0, U0, A0, R0]).T
## 
##     output = pd.DataFrame(columns=[&quot;day&quot;, &quot;S&quot;, &quot;U&quot;, &quot;A&quot;, &quot;R&quot;])
##     j = 0
##     vect = vect_initial.copy()
## 
##     while j &lt; i:
##         vectplus1 = np.zeros([4])
##         S = vect[0]
##         U = vect[1]
##         A = vect[2]
##         R = vect[3]
##         vectplus1[0] = S - p1 * S * (A + U) + p2 * U
##         vectplus1[1] = U + p1 * S * (A + U) - p2 * U - p3 * U
##         vectplus1[2] = A + p3 * U + p5 * (A + U) * R - p4 * A
##         vectplus1[3] = R + p4 * A - p5 * (A + U) * R
##         output.loc[j] = np.concatenate((np.array([j]), vectplus1.T))
##         vect = vectplus1.copy()
##         j += 1
## 
##     plt.plot(output[&quot;day&quot;], output[&quot;S&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;U&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;A&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;R&quot;])
##     plt.title(
##         &quot;p1=&quot;
##         + str(p1)
##         + &quot;, p2=&quot;
##         + str(p2)
##         + &quot;, p3=&quot;
##         + str(p3)
##         + &quot;, p4=&quot;
##         + str(p4)
##         + &quot;, p5=&quot;
##         + str(p5)
##     )
##     plt.legend([&quot;S&quot;, &quot;U&quot;, &quot;A&quot;, &quot;R&quot;])</code></pre>
</div>
<div id="appendix-7-python-code-for-simulating-20-compartment-suar-model" class="section level2">
<h2>Appendix 7: Python code for simulating 20 compartment SUAR model</h2>
<pre><code>## def SUAR_20(aging_rate, birth_rate, death_rate, I, P, X0, steps):
##     C = pd.DataFrame(columns=[&quot;s&quot;, &quot;t&quot;, &quot;a&quot;, &quot;r&quot;], dtype=&quot;float128&quot;)
##     T = pd.DataFrame(columns=[&quot;s&quot;, &quot;t&quot;, &quot;a&quot;, &quot;r&quot;], dtype=&quot;float128&quot;)
##     Y = pd.DataFrame(columns=[&quot;s&quot;, &quot;t&quot;, &quot;a&quot;, &quot;r&quot;], dtype=&quot;float128&quot;)
##     A = pd.DataFrame(columns=[&quot;s&quot;, &quot;t&quot;, &quot;a&quot;, &quot;r&quot;], dtype=&quot;float128&quot;)
##     S = pd.DataFrame(columns=[&quot;s&quot;, &quot;t&quot;, &quot;a&quot;, &quot;r&quot;], dtype=&quot;float128&quot;)
## 
##     (n_age_groups, n_status) = np.shape(X0)
##     itterations = 0
##     while itterations &lt; steps:
##         C.loc[itterations] = X0[0]
##         T.loc[itterations] = X0[1]
##         Y.loc[itterations] = X0[2]
##         A.loc[itterations] = X0[3]
##         S.loc[itterations] = X0[4]
## 
##         i = 0
## 
##         IE = np.matmul(I, X0)
## 
##         Xn = np.zeros(np.shape(X0))
## 
##         while i &lt; n_age_groups:
##             group_vect = X0[i].copy()
##             s = group_vect[0]
##             t = group_vect[1]
##             a = group_vect[2]
##             r = group_vect[3]
##             interaction_neg = np.sum(IE[i][[1, 2]])
##             interaction_pos = np.sum(IE[i][[0, 3]])
## 
##             Xn[i][0] = (
##                 s - (s * P[i][0] * interaction_neg) + t * P[i][1] * interaction_pos
##             )
##             Xn[i][1] = (
##                 t
##                 + (s * P[i][0] * interaction_neg)
##                 - t * P[i][1] * interaction_pos
##                 - t * P[i][2]
##             )
##             Xn[i][2] = (
##                 a
##                 + t * P[i][2]
##                 + r * P[i][4] * interaction_neg
##                 - a * P[i][3] * interaction_pos
##             )
##             Xn[i][3] = r - r * P[i][4] * interaction_neg + a * P[i][3] * interaction_pos
## 
##             i += 1
## 
##         Xn_aged = np.zeros(np.shape(X0))
## 
##         i = 0
##         j = 0
## 
##         while i &lt; n_age_groups:
##             j = 0
##             while j &lt; n_status:
##                 if i == 0:
##                     if j == 0:
##                         Xn_aged[i][j] = Xn[i][j] * (
##                             1 - aging_rate - death_rate[i][j]
##                         ) + birth_rate * sum(Xn[2] + Xn[3])
##                 j += 1
##             i += 1
## 
##         itterations += 1</code></pre>
</div>
<div id="appendix-8-python-code-for-simulating-5-compartment-suar-model" class="section level2">
<h2>Appendix 8: Python code for simulating 5 compartment SUAR model</h2>
<pre><code>## def SUAR_5(p1, p2, p3, p4, p5, b, d, S0, U0, A0, R0, i):
##     vect_initial = np.array([S0, U0, A0, R0]).T
## 
##     output = pd.DataFrame(columns=[&quot;day&quot;, &quot;S&quot;, &quot;U&quot;, &quot;A&quot;, &quot;R&quot;])
##     j = 0
##     vect = vect_initial.copy()
## 
##     while j &lt; i:
##         vectplus1 = np.zeros([4])
##         S = vect[0]
##         U = vect[1]
##         A = vect[2]
##         R = vect[3]
##         vectplus1[0] = (
##             S - p1 * S * (A + U) + p2 * U * (S + R) - d[0] * S + b * (S + U + A + R)
##         )
##         vectplus1[1] = U + p1 * S * (A + U) - p2 * U * (S + R) - p3 * U - d[1] * U
##         vectplus1[2] = A + p3 * U + p5 * (A + U) * R - p4 * A * (R + S) - d[2] * A
##         vectplus1[3] = R + p4 * A * (S + R) - p5 * (A + U) * R - d[3] * R
## 
##         output.loc[j] = np.concatenate((np.array([j]), vectplus1.T))
##         vect = vectplus1.copy()
##         j += 1
## 
##     output[&quot;pop&quot;] = output[&quot;S&quot;] + output[&quot;U&quot;] + output[&quot;A&quot;] + output[&quot;R&quot;]
##     plt.plot(output[&quot;day&quot;], output[&quot;S&quot;] / output[&quot;pop&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;U&quot;] / output[&quot;pop&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;A&quot;] / output[&quot;pop&quot;])
##     plt.plot(output[&quot;day&quot;], output[&quot;R&quot;] / output[&quot;pop&quot;])
##     plt.title(
##         &quot;Portion: p1=&quot;
##         + str(p1)
##         + &quot;, p2=&quot;
##         + str(p2)
##         + &quot;, p3=&quot;
##         + str(p3)
##         + &quot;, p4=&quot;
##         + str(p4)
##         + &quot;, p5=&quot;
##         + str(p5)
##     )
##     plt.legend([&quot;S&quot;, &quot;U&quot;, &quot;A&quot;, &quot;R&quot;])</code></pre>
</div>
<div id="appendix-9-python-code-for-simulating-5-compartment-dimensionless-suar-model" class="section level2">
<h2>Appendix 9: Python code for simulating 5 compartment dimensionless SUAR model</h2>
<pre><code>## def SUAR_norm(p1, p2, p3, p4, p5, d, S0, U0, A0, R0, i, h, plot=True):
##     vect_initial = np.array([S0, U0, A0, R0]).T
## 
##     output = pd.DataFrame(columns=[&quot;day&quot;, &quot;s&quot;, &quot;u&quot;, &quot;a&quot;, &quot;r&quot;])
##     j = 0
##     vect = vect_initial.copy()
## 
##     ds = d[0]
##     du = d[1]
##     da = d[2]
##     dr = d[3]
## 
##     while j &lt; i:
##         vectplus1 = np.zeros([4])
##         s = vect[0]
##         u = vect[1]
##         a = vect[2]
##         r = vect[3]
##         vectplus1[0] = s + h * (
##             (-s * p1 * (u + a) + u * p2 * (s + r) - ds * s + 1)
##             - s * (1 - ds * s - du * u - da * a - dr * r)
##         )
##         vectplus1[1] = u + h * (
##             (s * p1 * (u + a) - u * p2 * (s + r) - u * p3 - du * u)
##             - u * (1 - ds * s - du * u - da * a - dr * r)
##         )
##         vectplus1[2] = a + h * (
##             (u * p3 - a * p4 * (s + r) + r * p5 * (u + a) - da * a)
##             - a * (1 - ds * s - du * u - da * a - dr * r)
##         )
##         vectplus1[3] = r + h * (
##             (a * p4 * (s + r) - r * p5 * (u + a) - dr * r)
##             - r * (1 - ds * s - du * u - da * a - dr * r)
##         )
##         output.loc[j] = np.concatenate((np.array([j * h]), vectplus1.T))
##         vect = vectplus1.copy()
##         j += 1
##     if plot:
##         plt.plot(output[&quot;day&quot;], output[&quot;s&quot;])
##         plt.plot(output[&quot;day&quot;], output[&quot;u&quot;])
##         plt.plot(output[&quot;day&quot;], output[&quot;a&quot;])
##         plt.plot(output[&quot;day&quot;], output[&quot;r&quot;])
##         plt.title(
##             &quot;Portion: p1=&quot;
##             + str(p1)
##             + &quot;, p2=&quot;
##             + str(p2)
##             + &quot;, p3=&quot;
##             + str(p3)
##             + &quot;, p4=&quot;
##             + str(p4)
##             + &quot;, p5=&quot;
##             + str(p5)
##         )
##         plt.legend([&quot;S&quot;, &quot;U&quot;, &quot;A&quot;, &quot;R&quot;])
##         return
##     else:
##         return [s, u, a, r]</code></pre>
</div>
</div>
]]></content>
        </item>
        
    </channel>
</rss>

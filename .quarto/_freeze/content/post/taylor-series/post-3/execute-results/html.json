{
  "hash": "b7f6e1b24ce10f7923e7c098e929f357",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Making my ODE solver solve ODEs\"\nauthor: 'Alfie Chadwick'\ndate: '2024-01-12'\nlastmod: \"`r Sys.Date()`\"\ntags: ['Calculus', 'Algebra','Python']\n---\n\n\n\n\nAfter writing out the [last post](post-2.html) where I wrote out a python library for using an improved version of Euler's method to solve ODEs. But so far, we haven't been solving ODES, instead we have just been taking an initial value and iterating it over the length of a domain. To To make the ODE estimator work, we need to ensure that the conditions of the ODE are met at each step.\n\n# Simplifying ODEs: Constant-Linear ODEs\n\nODEs are often categorized as linear or non-linear. Linear ODEs take the form $a_0(x)y + a_1(x)y' + ... + a_n(x)y^{n} = b(x)$, with both $a$ and $b$ representing functions of $x$, while  Non-linear equations are all the others. In our solver's context, we'll concentrate on a subset I've termed \"constant-linear\" ODEs, characterized by constant coefficients for $y$ terms and a linear function of $x$ for $b$. Specifically, a constant-linear ODE looks like $a_0y + a_1y' + ... + a_ny^{n} = bx + c$.\n\nThis may seem like a very restrictive requirement, but there are many famous examples of this kind of equation including:\n\n\n1. Simple Harmonic Motion:\n   $$ y'' + \\omega^2 y = 0 $$\n\n2. Radioactive Decay:\n   $$ \\frac{dy}{dt} = -\\lambda y $$\n\n3. RC Circuit Equation:\n   $$ y' + \\frac{1}{RC} y = 0 $$\n\n4. Damped Harmonic Oscillator:\n   $$ y'' + 2\\gamma y' + \\omega_0^2 y = 0 $$\n\n5. Heat Equation (One-Dimensional):\n   $$ u'' - \\frac{1}{\\alpha} u'= 0 $$\n\n6. Exponential Growth or Decay:\n   $$ y' = ky $$\n\n# A Quick Diversion: ODEs in Vector Space\n\nPivoting for a moment, I want to take a quick moment to reframe how we are imagining ODEs. Most of the time, we see ODEs as curves in space and/or time, but I want to reframe them as planes in a vector space.\n\nEach point in this vector space describes the state of a point along a curve, such that a values of the vector give:\n\n$$\\begin{bmatrix}\n1\\\\\nx\\\\\ny(x)\\\\\ny'(x)\\\\\ny''(x)\\\\\n...\\\\\ny^{n}(x)\\\\\n\\end{bmatrix} \n$$\n\nThis means that an ODE can be defined by a plane that contains all the points which meet the requirements of the ODE.\n\nFor example, for the equation $y' = 2x$ this plane looks like:\n\n::: {#d84a74ec .cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport mplcatppuccin\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nmpl.style.use(\"macchiato\")\n\n# Create a grid of values for x and y\nx = np.linspace(0, 10, 100)\ny = np.linspace(0, 100, 100)\nx, y = np.meshgrid(x, y)\n\n# Calculate corresponding z\nz = (2*x)\n\n# Create a figure and a 3D axis\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(x, z,y, alpha = 0.7)\n\n# Set labels\nax.set_xlabel('X')\nax.set_zlabel('Y')\nax.set_ylabel(\"Y'\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_6239/3200397363.py:3: DeprecationWarning: The catppuccin-matplotlib package is deprecated, please upgrade to https://github.com/catppuccin/python (pip install catppuccin)\n\n\n  import mplcatppuccin\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](post-3_files/figure-html/cell-2-output-2.png){width=410 height=396}\n:::\n:::\n\n\nThen a specific solution to the ODE exists as a curve that sits on this plane. For example, for the IVP that starts at (0,0), the solution follows this curve:\n\n::: {#3a6a92dd .cell execution_count=2}\n``` {.python .cell-code}\nLx = np.linspace(0, 10, 100)\nLy = np.array([x**2 for x in Lx])\n\n# Create masks for the conditions\nmask = (Lx <= 10) & (Lx >= 0) & (Ly <= 100) & (Ly >= 0)\n\n# Now apply the mask to both arrays to exclude unwanted values\nfiltered_Lx = Lx[mask]\nfiltered_Ly = Ly[mask]\n\nLz = (2*filtered_Lx) +1\n\n# Create a new figure\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d',computed_zorder=False)\n\n# Plot surface and line\nax.plot_surface(x, z,y, zorder=0,alpha = 0.7)\nax.plot(filtered_Lx, Lz, filtered_Ly, color='r',linestyle='dashed' , zorder=1)\n\n\n# Set labels\nax.set_xlabel('X')\nax.set_zlabel('Y')\nax.set_ylabel(\"Y'\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post-3_files/figure-html/cell-3-output-1.png){width=410 height=396}\n:::\n:::\n\n\n## But Why Does This Matter\n\nThe reason that we want to reframe ODEs in this way is because of the following fact:\n\n**For all constant-linear ODEs, we can express the ODE as a matrix such that applying it to any point in the vector space would map any point to a valid point on the curve defined by the ODE**\n\\\n\nLooking at the equations above, these matrices ($T$) are:\n\n\n1. Simple Harmonic Motion:\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0\\\\\n0 & 0 & -\\omega^2 & 0 & 0\\\\\n\\end{bmatrix}\n$$\n\n2. Radioactive Decay:\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & -\\lambda & 0\\\\\n\\end{bmatrix}$$\n\n3. RC Circuit Equation:\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & \\frac{-1}{RC} & 0\\\\\n\\end{bmatrix}$$\n\n4. Damped Harmonic Oscillator:\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0\\\\\n0 & 0 & -\\omega^2 & -2\\gamma & 0\\\\\n\\end{bmatrix}$$\n\n5. Heat Equation (One-Dimensional):\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & \\frac{1}{\\alpha} & 0\\\\\n\\end{bmatrix}$$\n\n6. Exponential Growth or Decay:\n$$T = \\begin{bmatrix}\n1 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & k & 0\\\\\n\\end{bmatrix}$$\n\n## Using these to fit ODEs\n\nNow that we can express the ODEs in the form of a matrix, we can implement these matriexies in the ODE solver package to make the solution fit the ode. \nIt's important here to note that I've diverted from my old definitions of $Y$ here, where the first element of the vector is $y(x)$.\n\nTo make a step in the approximation we use the following equation:\n\n$$ \\begin{bmatrix}\n1 \\\\\nx+h \\\\ \ny(x+h)\\\\\ny'(x+h)\\\\\ny''(x+h)\\\\\n...\\\\\ny^{n}(x+h)\\\\\n\\end{bmatrix} =  S \\cdot \\begin{bmatrix}\n1 \\\\\nx\\\\\ny(x)\\\\\ny'(x)\\\\\ny''(x)\\\\\n...\\\\\ny^{n}(x)\\\\\n\\end{bmatrix}\n\\epsilon $$ \n\nWhere $S$ is:\n$$ \\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 & ... & 0 \\\\\nh & 1 & 0 & 0 & 0 & ... & 0 \\\\\n0 & 0 & 1 & \\frac{h}{1!} & \\frac{h^2}{2!} &  ... & \\frac{h^n}{n!}\\\\\n0 & 0 & 0 & 1 & \\frac{h}{1!} &  ... & \\frac{h^{n-1}}{(n-1)!}\\\\\n0 & 0 & 0 & 0 & 1 &  ... & \\frac{h^{n-2}}{(n-2)!}\\\\\n... & ... & ... & ... &  ... & ...\\\\\n0 & 0 & 0 & 0 & 0 &  ... & 1\\\\\n\\end{bmatrix}$$\n\nWhen making this step, the error in the approximation will move the point away from the plane that contains all valid solutions to the ODE, and therefore we will have to snap it back using one of the transformation matrices ($T$).\n\nImplementing this method in our python library:\n\n::: {#0a4d69f5 .cell execution_count=3}\n``` {.python .cell-code}\ndef expanded_euler(dims, h):\n    step_matrix = np.zeros((dims, dims))\n    for i in range(dims):\n        for j in range(i, dims):\n            # Is 1, and h at j-i =0, 1 respectively\n            step_matrix[i, j] = h ** (j - i) / math.factorial(j - i)\n    expanded_matrix = add_x_and_1(step_matrix, h)\n    return expanded_matrix\n\n\ndef add_x_and_1(original_matrix, h):\n    new_size = len(original_matrix) + 2\n    new_matrix = np.zeros((new_size, new_size), dtype=original_matrix.dtype)\n\n    # Set the 2x2 top left matrix\n    new_matrix[0:2, 0:2] = [[1, 0], [h, 1]]\n\n    # Copy the original matrix to the bottom right of the new matrix.\n    new_matrix[2:, 2:] = original_matrix\n    return new_matrix\n\n\ndef linear(y, step_matrix_generator, transformation_matrix, steps=10, h=0.1):\n    dims = len(y) - 2\n    step_matrix = transformation_matrix @ step_matrix_generator(dims, h)\n    output_list = []\n\n    y_n = y.copy()\n    i = 0\n    while i < steps:\n        y_n = step_matrix @ y_n\n        output_list.append(y_n)\n        i += 1\n```\n:::\n\n\nBind this machinery together, and you get a tool capable of tackling the initial example of $y' = 2x$ passing through the point (0,0):\n\n::: {#ac54dae0 .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nimport math\n\n\nclass Solution:\n    def __init__(self, input_list: list):\n        solution_list = sorted(input_list, key=lambda x: x[1])\n\n        dims = len(solution_list[0]) - 2\n        self.x = np.array([x[1] for x in input_list])\n\n        value_lists = [[] for _ in range(dims)]\n\n        for v in input_list:\n            for i in range(dims):\n                value_lists[i].append(v[i + 2])\n\n        for i in range(dims):\n            self.__dict__[f\"y_{i}\"] = np.array(value_lists[i])\n\n    def interpolate(self, x, y_n):\n        \"\"\"\n        allows you to get any value from the solution by interpolating the points\n\n        \"\"\"\n        y_values = self.__dict__[f\"y_{y_n}\"]\n\n        x_max_index = np.where(self.x >= x)[0][0]\n        x_min_index = np.where(self.x <= x)[0][-1]\n\n        x_at_x_max = self.x[x_max_index]\n        x_at_x_min = self.x[x_min_index]\n\n        y_at_x_max = y_values[x_max_index]\n        y_at_x_min = y_values[x_min_index]\n\n        slope = (y_at_x_max - y_at_x_min) / (x_at_x_max - x_at_x_min)\n\n        value = y_at_x_min + slope * (x - x_at_x_min)\n        return value\n\ndef linear(y, step_matrix_generator, transformation_matrix, steps=10, h=0.1):\n    dims = len(y) - 2\n    step_matrix = transformation_matrix @ step_matrix_generator(dims, h)\n    output_list = []\n\n    y_n = y.copy()\n    i = 0\n    while i < steps:\n        y_n = step_matrix @ y_n\n        output_list.append(y_n)\n        i += 1\n\n    return Solution(output_list)\n```\n:::\n\n\n::: {#b337b78e .cell execution_count=5}\n``` {.python .cell-code}\ninit_y = [1,0,0,0] #[1,x,y,y']\ntransformation_matrix = np.array([\n   [ 1,0,0,0 ],\n   [ 0,1,0,0 ],\n   [ 0,0,1,0 ],\n   [ 0,2,0,0 ]\n])\nsolution = linear(\n    init_y,\n    expanded_euler,\n    transformation_matrix,\n    steps=100, h=0.01)\n```\n:::\n\n\n::: {#66141434 .cell execution_count=6}\n``` {.python .cell-code}\nplt.plot(solution.x, solution.y_0, label='Approximated Solution')\nplt.plot(solution.x, solution.x**2, label='True Solution', linestyle='--')\nplt.xlabel('x') # Label for the x-axis\nplt.ylabel('y') # Label for the y-axis\nplt.grid(True) # Show a grid for better readability\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](post-3_files/figure-html/cell-7-output-1.png){width=589 height=429}\n:::\n:::\n\n\n# What's Next?\n\nThis method seems to work pretty well and follows the true solution pretty closely. I'm going to stop here for now but there are many things on my wishlist that I want to build in later posts. This includes:\n\n- Solving IVPs which aren't constant-linear\n- Solving BVPs\n- Applying this method to PDEs\n\nStay tuned for more posts in this series where I try to implement these features into my solver!\n\n",
    "supporting": [
      "post-3_files"
    ],
    "filters": [],
    "includes": {}
  }
}
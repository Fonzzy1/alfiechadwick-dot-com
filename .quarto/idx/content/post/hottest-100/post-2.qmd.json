{"title":"A Follow Up on my Hottest 100 Predictions","markdown":{"yaml":{"title":"A Follow Up on my Hottest 100 Predictions","author":"Alfie Chadwick","date":"2024-02-03","lastmod":"`r Sys.Date()`","tags":["Music","ML"]},"headingText":"Top 20","containsRefs":false,"markdown":"\n\n\n```{R setup,  include=FALSE}\n\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(patchwork)\nlibrary(lubridate)\nlibrary(xgboost)\nlibrary(catppuccin)\n\nknitr::opts_chunk$set( echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE)\n\n\ntheme_dark_catppuccino <- function(base_size = 11, base_family = \"\") {\n  theme_minimal(base_size = base_size, base_family = base_family) +\n    theme(\n      # Define colors\n      text = element_text(color = \"#cad3f5\"),\n      strip.text = element_text(colour = '#cad3f5'),\n      \n      # Background colors\n      plot.background = element_rect(fill = \"#24273a\", color = NA),\n      panel.background = element_rect(fill = \"#1e2030\", color = NA),\n      plot.margin = margin(2, 2, 2, 2, \"pt\"),\n\n      # Grid colors\n      panel.grid.major = element_line(color = \"#494d64\", size = 0.25),\n      panel.grid.minor = element_line(color = \"#494d64\", size = 0.25),\n      \n      # Axis colors and ticks\n      axis.ticks = element_line(color = \"#cad3f5\"),\n      axis.text = element_text(color = \"#cad3f5\"),\n      axis.title = element_text(color = \"#cad3f5\"),\n      axis.line = element_line(color = \"#cad3f5\"),\n      \n      # Legend colors\n      legend.background = element_rect(fill = \"#363a4f\"),\n      legend.text = element_text(color = \"#cad3f5\"),\n      legend.title = element_text(color = \"#cad3f5\", face = \"bold\"),\n      legend.position = \"none\",\n\n      # Title and subtitle\n      plot.title = element_text(color = \"#b7bdf8\", size = base_size * 1.2, \n                                hjust = 0.5, face = \"bold\"),\n      plot.subtitle = element_text(color = \"#b7bdf8\", size = base_size * 0.9,\n                                   hjust = 0.5),\n                                   \n      # Caption\n      plot.caption = element_text(color = \"#f4dbd6\", hjust = 0.5, \n                                  size = base_size * 0.8)\n    )\n}\n\ntheme_set(theme_dark_catppuccino())\n\n```\n\n```{R dataset}\n\ndata_cols <- c(\n  \"weeks_with_more_than_7\",\n  \"peak_week_JJJ\",\n  \"peak_plays_JJJ\",\n  \"first_play\",\n  \"total_plays\",\n  \"weeks_in_charts\",\n  \"peak_in_charts\",\n  \"chart_score\"\n)\n\nclean_artist_name <- function(artist_string) {\n  # Convert the string to lowercase\n  artist_string <- tolower(artist_string)\n  \n  # remove any text within parentheses or \n  artist_string <- gsub(\"\\\\(.+?\\\\)\", \"\", artist_string)\n  # Remove content in square brackets\n  artist_string <- gsub(\"\\\\[.+?\\\\]\", \"\", artist_string)\n  \nmain_artist <- unlist(strsplit(artist_string, \" feat | featuring | ft | with | x | and | & | vs |, \"))[1]\n\n    main_artist <- iconv(main_artist, from = \"UTF-8\", to = \"ASCII//TRANSLIT\")\n    main_artist <- gsub(\"[[:punct:]]\", \"\", main_artist)\n  \n  # trim leading and trailing whitespace\n  main_artist <- trimws(main_artist)\n  \n  return(main_artist)\n}\n\nclean_song_name <- function(song_string) {\n  # Convert the string to lowercase\n  song_string <- tolower(song_string)\n  \n  # remove any text within parentheses or \n  song_string <- gsub(\"\\\\(.+?\\\\)\", \"\", song_string)\n  # Remove content in square brackets\n  song_string <- gsub(\"\\\\[.+?\\\\]\", \"\", song_string)\n  \n  songname <- unlist(strsplit(song_string, \" feat | featuring | ft | with \"))[1]\n  \n  # trim leading and trailing whitespace\n  songname <- trimws(songname)\n  \n  return(songname)\n}\n\n\nresults <- read.csv('data/2023_results.csv')\nxgb_model <- xgb.load('data/xgb_model.bin')\ninferance <- readRDS(\"data/inferance.rds\")\ninferance[data_cols] <- lapply(inferance[data_cols], as.numeric)\ninf <- as.matrix(inferance[, data_cols])\npredictions <- predict(xgb_model, inf)\ninferance$predicted_rank <- predictions\n\nresults <- results %>%\n  mutate(\n    Song = map_chr(Song, clean_song_name),\n    Artist = map_chr(Artist, clean_artist_name)\n  )\n\nmy_100 <- inferance  %>% \n  mutate(predicted_rank = rank(predicted_rank, ties.method = \"first\")) %>%\n  filter(predicted_rank < 101)\n```\n\nIn my [last post](post.html) I ended by planting my flag and making my predictions for the Hottest 100 for 2023. And on first glance, I'm pretty happy with myself, picking not only the top song, but a good chunk of the top 20. So today I just want to do a quick follow up on how I did.\n\n\n```{R top-20}\n\nresults %>% \n  left_join(my_100) %>%\n  select(Song, Artist, rank, predicted_rank) %>%\n  arrange(rank) %>%  # Sort by rank\n  select(Song, Artist,Predicted =  predicted_rank) %>%\n  slice_head(n = 20) %>%       # Take the first 20 rows after sorting\n  knitr::kable()\n```\n\nThe top 10 seems okay, but i did miss a lot of the top 20 completely. I seemed to be undervaluing Australian artists such as Dom Dolla, Spacey Jane, and G Flip, as well as EDM as a genre, which made up a much greater portion of the top 20 than I predicted.\n\n\n# Snubbed Songs\n\n```{R snubs}\n\nmy_100 %>%\n  left_join(results) %>%\n  filter(is.na(rank)) %>%\n  select(Song, Artist, rank, predicted_rank) %>%\n  arrange(predicted_rank) %>%  # Sort by rank\n  select(Song, Artist,Predicted =  predicted_rank) %>%\n  knitr::kable()\n```\n\nSo there were 55 songs in my predictions that didn't make it into the countdown, including 3 of my top 20. Funily enough though, a lot of my predictions seemed to line up with peoples opions online with [Love Type](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1b24c/?utm_source=share&utm_medium=web2x&context=3), [Super Ego](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk16o08/?utm_source=share&utm_medium=web2x&context=3) and [Adored](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1hqcl/?utm_source=share&utm_medium=web2x&context=3) all being mentioned as snubs from the hottest 100.\n\n\n# Surprise Songs\n\n```{R suroprise}\n\n\nmy_100 %>%\n  right_join(results) %>%\n  filter(is.na(predicted_rank)) %>%\n  select(Song, Artist, rank) %>%\n  arrange(rank) %>%  # Sort by rank\n  select(Song, Artist, rank) %>%\n  mutate(Song = if_else(nchar(Song) > 20, paste0(substr(Song, 1, 17), \"...\"), Song)) %>%\n  knitr::kable()\n```\n\nWith 55 snubs, we are going to have 55 surprise songs. There doesn't seem to be  a massive trend here. G flip only made it into my countdown twice, so 5 of their songs are in this list. Its also interesting seeing which conventionally popular songs are part of this list.  Boy's a liar pt. 2  by Pinkpantheress and All American-Bitch which peaked at 2 and 10 on the aria charts were left out in my predictions, even though it predicted similar chart toppers in the top 10.\n\n```{R suroprise-comps}\n\n# Filter the songs of interest\nfiltered_songs <- inferance %>%\n  filter(Song %in% c(\"all-american bitch\", \"boy's a liar pt. 2\", \"paint the town red\", \"vampire\")) %>%\n  select(- first_play)\n\n\n# Melt the data for easy plotting using 'pivot_longer' from tidyr package\nlong_data <- filtered_songs %>%\n  pivot_longer(cols = data_cols[!data_cols %in% 'first_play'], names_to = \"Metrics\", values_to = \"Values\")\n\nggplot(long_data, aes(x = Song, y = Values, fill = Song)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.7)) +\n  facet_wrap(~ Metrics, scales = \"free_y\") + # Faceting by metrics, with separate y scales\n  labs(x = \"Song\", y = \"Value\", title = \"Comparison of Songs Across Inferance Features\") +\n  scale_fill_catppuccin(palette=\"macchiato\",  reverse = FALSE) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\nLooking at these plots, it seems that the chart data for these songs didn't correctly join with the play data from triple J. After cleaning the names, I was hoping that there wouldn't be too much of a discrepancy. However, in the ARIA charts, \"all-american bitch\" is listed as \"all-american b\\*\\*ch,\" and \"boys a liar pt. 2\" is listed as \"boys a liar\". This kind of discrepancy is probably present throughout my dataset and may have led to some major inaccuracies. However, it is also just part of life when dealing with text data.\n\n# Did I do better than Warm Tuna?\n\nPart of my mission when setting out to make these predictions was to outperform 100 Warm Tunas, who utilize a compilation of social media posts to formulate their predictions.\n\n```{R warm_tuna_comp}\n\nwarm_tuna <- read_csv('data/warm_tuna_2023.csv')\nwarm_tuna <- warm_tuna %>%\n  mutate(\n    Song = map_chr(Song, clean_song_name),\n    Artist = map_chr(Artist, clean_artist_name),\n    predicted_rank = Rank\n  ) %>%\n  select(-Rank)\n\n\nresults %>% \n  arrange(rank) %>%  # Sort by rank\n  left_join(warm_tuna) %>%\n  select(Song, Artist, rank, warm_tuna = predicted_rank) %>%\n  left_join(my_100) %>%\n  select(Song, Artist, rank, warm_tuna, my_rankning = predicted_rank) %>%\n  slice_head(n = 20) %>%       # Take the first 20 rows after sorting\n  knitr::kable()\n\n```\n\nStraight away, I can see that warm tuna did better than me, but by how much?\n\nSo, I made up a quick statistic to see how far off our predictions were. This is the sum of the magnitudes of the differences between the predicted score and the actual score. If a song didn't make the top 100, it's given the equivalent rank of 101. I then divide this by 100 to get the average deviation for each prediction.\n\n```{R warm_tuna_comp_res}\n\nresults_summary <- results %>% \n  arrange(rank) %>%  # Sort by rank\n  left_join(warm_tuna) %>%\n  select(Song, Artist, rank, warm_tuna = predicted_rank) %>%\n  left_join(my_100) %>%\n  select(Song, Artist, rank, warm_tuna, my_ranking = predicted_rank) %>%\n  mutate(warm_tuna_score = replace_na(warm_tuna, 101) - rank) %>%\n  mutate(my_score = replace_na(my_ranking, 101) - rank) %>%\n  summarize(warm_tunas_avg = sum(abs(warm_tuna_score))/100, my_avg = sum(abs(my_score))/100)\n\n# Print the results with the requested labels\ncat(\"my score:\", results_summary$my_avg, \"\\n\")\ncat(\"warm tuna's score:\", results_summary$warm_tunas_avg, \"\\n\")\n```\n\nSo from these statistics, we can see that my predictions were, on average, about 10 places more off than warm tuna's.\n\n\n# Next Year?\n\nI reckon this method still has promise, but I need to sort out the name joining issue to ensure that my method is working at its maximum potential. I also want to include genre and artist country into it since it seemed to be an important factor in the final rank that I didn't account for.\n","srcMarkdownNoYaml":"\n\n\n```{R setup,  include=FALSE}\n\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(patchwork)\nlibrary(lubridate)\nlibrary(xgboost)\nlibrary(catppuccin)\n\nknitr::opts_chunk$set( echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE)\n\n\ntheme_dark_catppuccino <- function(base_size = 11, base_family = \"\") {\n  theme_minimal(base_size = base_size, base_family = base_family) +\n    theme(\n      # Define colors\n      text = element_text(color = \"#cad3f5\"),\n      strip.text = element_text(colour = '#cad3f5'),\n      \n      # Background colors\n      plot.background = element_rect(fill = \"#24273a\", color = NA),\n      panel.background = element_rect(fill = \"#1e2030\", color = NA),\n      plot.margin = margin(2, 2, 2, 2, \"pt\"),\n\n      # Grid colors\n      panel.grid.major = element_line(color = \"#494d64\", size = 0.25),\n      panel.grid.minor = element_line(color = \"#494d64\", size = 0.25),\n      \n      # Axis colors and ticks\n      axis.ticks = element_line(color = \"#cad3f5\"),\n      axis.text = element_text(color = \"#cad3f5\"),\n      axis.title = element_text(color = \"#cad3f5\"),\n      axis.line = element_line(color = \"#cad3f5\"),\n      \n      # Legend colors\n      legend.background = element_rect(fill = \"#363a4f\"),\n      legend.text = element_text(color = \"#cad3f5\"),\n      legend.title = element_text(color = \"#cad3f5\", face = \"bold\"),\n      legend.position = \"none\",\n\n      # Title and subtitle\n      plot.title = element_text(color = \"#b7bdf8\", size = base_size * 1.2, \n                                hjust = 0.5, face = \"bold\"),\n      plot.subtitle = element_text(color = \"#b7bdf8\", size = base_size * 0.9,\n                                   hjust = 0.5),\n                                   \n      # Caption\n      plot.caption = element_text(color = \"#f4dbd6\", hjust = 0.5, \n                                  size = base_size * 0.8)\n    )\n}\n\ntheme_set(theme_dark_catppuccino())\n\n```\n\n```{R dataset}\n\ndata_cols <- c(\n  \"weeks_with_more_than_7\",\n  \"peak_week_JJJ\",\n  \"peak_plays_JJJ\",\n  \"first_play\",\n  \"total_plays\",\n  \"weeks_in_charts\",\n  \"peak_in_charts\",\n  \"chart_score\"\n)\n\nclean_artist_name <- function(artist_string) {\n  # Convert the string to lowercase\n  artist_string <- tolower(artist_string)\n  \n  # remove any text within parentheses or \n  artist_string <- gsub(\"\\\\(.+?\\\\)\", \"\", artist_string)\n  # Remove content in square brackets\n  artist_string <- gsub(\"\\\\[.+?\\\\]\", \"\", artist_string)\n  \nmain_artist <- unlist(strsplit(artist_string, \" feat | featuring | ft | with | x | and | & | vs |, \"))[1]\n\n    main_artist <- iconv(main_artist, from = \"UTF-8\", to = \"ASCII//TRANSLIT\")\n    main_artist <- gsub(\"[[:punct:]]\", \"\", main_artist)\n  \n  # trim leading and trailing whitespace\n  main_artist <- trimws(main_artist)\n  \n  return(main_artist)\n}\n\nclean_song_name <- function(song_string) {\n  # Convert the string to lowercase\n  song_string <- tolower(song_string)\n  \n  # remove any text within parentheses or \n  song_string <- gsub(\"\\\\(.+?\\\\)\", \"\", song_string)\n  # Remove content in square brackets\n  song_string <- gsub(\"\\\\[.+?\\\\]\", \"\", song_string)\n  \n  songname <- unlist(strsplit(song_string, \" feat | featuring | ft | with \"))[1]\n  \n  # trim leading and trailing whitespace\n  songname <- trimws(songname)\n  \n  return(songname)\n}\n\n\nresults <- read.csv('data/2023_results.csv')\nxgb_model <- xgb.load('data/xgb_model.bin')\ninferance <- readRDS(\"data/inferance.rds\")\ninferance[data_cols] <- lapply(inferance[data_cols], as.numeric)\ninf <- as.matrix(inferance[, data_cols])\npredictions <- predict(xgb_model, inf)\ninferance$predicted_rank <- predictions\n\nresults <- results %>%\n  mutate(\n    Song = map_chr(Song, clean_song_name),\n    Artist = map_chr(Artist, clean_artist_name)\n  )\n\nmy_100 <- inferance  %>% \n  mutate(predicted_rank = rank(predicted_rank, ties.method = \"first\")) %>%\n  filter(predicted_rank < 101)\n```\n\nIn my [last post](post.html) I ended by planting my flag and making my predictions for the Hottest 100 for 2023. And on first glance, I'm pretty happy with myself, picking not only the top song, but a good chunk of the top 20. So today I just want to do a quick follow up on how I did.\n\n# Top 20\n\n```{R top-20}\n\nresults %>% \n  left_join(my_100) %>%\n  select(Song, Artist, rank, predicted_rank) %>%\n  arrange(rank) %>%  # Sort by rank\n  select(Song, Artist,Predicted =  predicted_rank) %>%\n  slice_head(n = 20) %>%       # Take the first 20 rows after sorting\n  knitr::kable()\n```\n\nThe top 10 seems okay, but i did miss a lot of the top 20 completely. I seemed to be undervaluing Australian artists such as Dom Dolla, Spacey Jane, and G Flip, as well as EDM as a genre, which made up a much greater portion of the top 20 than I predicted.\n\n\n# Snubbed Songs\n\n```{R snubs}\n\nmy_100 %>%\n  left_join(results) %>%\n  filter(is.na(rank)) %>%\n  select(Song, Artist, rank, predicted_rank) %>%\n  arrange(predicted_rank) %>%  # Sort by rank\n  select(Song, Artist,Predicted =  predicted_rank) %>%\n  knitr::kable()\n```\n\nSo there were 55 songs in my predictions that didn't make it into the countdown, including 3 of my top 20. Funily enough though, a lot of my predictions seemed to line up with peoples opions online with [Love Type](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1b24c/?utm_source=share&utm_medium=web2x&context=3), [Super Ego](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk16o08/?utm_source=share&utm_medium=web2x&context=3) and [Adored](https://www.reddit.com/r/triplej/comments/1adh146/comment/kk1hqcl/?utm_source=share&utm_medium=web2x&context=3) all being mentioned as snubs from the hottest 100.\n\n\n# Surprise Songs\n\n```{R suroprise}\n\n\nmy_100 %>%\n  right_join(results) %>%\n  filter(is.na(predicted_rank)) %>%\n  select(Song, Artist, rank) %>%\n  arrange(rank) %>%  # Sort by rank\n  select(Song, Artist, rank) %>%\n  mutate(Song = if_else(nchar(Song) > 20, paste0(substr(Song, 1, 17), \"...\"), Song)) %>%\n  knitr::kable()\n```\n\nWith 55 snubs, we are going to have 55 surprise songs. There doesn't seem to be  a massive trend here. G flip only made it into my countdown twice, so 5 of their songs are in this list. Its also interesting seeing which conventionally popular songs are part of this list.  Boy's a liar pt. 2  by Pinkpantheress and All American-Bitch which peaked at 2 and 10 on the aria charts were left out in my predictions, even though it predicted similar chart toppers in the top 10.\n\n```{R suroprise-comps}\n\n# Filter the songs of interest\nfiltered_songs <- inferance %>%\n  filter(Song %in% c(\"all-american bitch\", \"boy's a liar pt. 2\", \"paint the town red\", \"vampire\")) %>%\n  select(- first_play)\n\n\n# Melt the data for easy plotting using 'pivot_longer' from tidyr package\nlong_data <- filtered_songs %>%\n  pivot_longer(cols = data_cols[!data_cols %in% 'first_play'], names_to = \"Metrics\", values_to = \"Values\")\n\nggplot(long_data, aes(x = Song, y = Values, fill = Song)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.7)) +\n  facet_wrap(~ Metrics, scales = \"free_y\") + # Faceting by metrics, with separate y scales\n  labs(x = \"Song\", y = \"Value\", title = \"Comparison of Songs Across Inferance Features\") +\n  scale_fill_catppuccin(palette=\"macchiato\",  reverse = FALSE) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\nLooking at these plots, it seems that the chart data for these songs didn't correctly join with the play data from triple J. After cleaning the names, I was hoping that there wouldn't be too much of a discrepancy. However, in the ARIA charts, \"all-american bitch\" is listed as \"all-american b\\*\\*ch,\" and \"boys a liar pt. 2\" is listed as \"boys a liar\". This kind of discrepancy is probably present throughout my dataset and may have led to some major inaccuracies. However, it is also just part of life when dealing with text data.\n\n# Did I do better than Warm Tuna?\n\nPart of my mission when setting out to make these predictions was to outperform 100 Warm Tunas, who utilize a compilation of social media posts to formulate their predictions.\n\n```{R warm_tuna_comp}\n\nwarm_tuna <- read_csv('data/warm_tuna_2023.csv')\nwarm_tuna <- warm_tuna %>%\n  mutate(\n    Song = map_chr(Song, clean_song_name),\n    Artist = map_chr(Artist, clean_artist_name),\n    predicted_rank = Rank\n  ) %>%\n  select(-Rank)\n\n\nresults %>% \n  arrange(rank) %>%  # Sort by rank\n  left_join(warm_tuna) %>%\n  select(Song, Artist, rank, warm_tuna = predicted_rank) %>%\n  left_join(my_100) %>%\n  select(Song, Artist, rank, warm_tuna, my_rankning = predicted_rank) %>%\n  slice_head(n = 20) %>%       # Take the first 20 rows after sorting\n  knitr::kable()\n\n```\n\nStraight away, I can see that warm tuna did better than me, but by how much?\n\nSo, I made up a quick statistic to see how far off our predictions were. This is the sum of the magnitudes of the differences between the predicted score and the actual score. If a song didn't make the top 100, it's given the equivalent rank of 101. I then divide this by 100 to get the average deviation for each prediction.\n\n```{R warm_tuna_comp_res}\n\nresults_summary <- results %>% \n  arrange(rank) %>%  # Sort by rank\n  left_join(warm_tuna) %>%\n  select(Song, Artist, rank, warm_tuna = predicted_rank) %>%\n  left_join(my_100) %>%\n  select(Song, Artist, rank, warm_tuna, my_ranking = predicted_rank) %>%\n  mutate(warm_tuna_score = replace_na(warm_tuna, 101) - rank) %>%\n  mutate(my_score = replace_na(my_ranking, 101) - rank) %>%\n  summarize(warm_tunas_avg = sum(abs(warm_tuna_score))/100, my_avg = sum(abs(my_score))/100)\n\n# Print the results with the requested labels\ncat(\"my score:\", results_summary$my_avg, \"\\n\")\ncat(\"warm tuna's score:\", results_summary$warm_tunas_avg, \"\\n\")\n```\n\nSo from these statistics, we can see that my predictions were, on average, about 10 places more off than warm tuna's.\n\n\n# Next Year?\n\nI reckon this method still has promise, but I need to sort out the name joining issue to ensure that my method is working at its maximum potential. I also want to include genre and artist country into it since it seemed to be an important factor in the final rank that I didn't account for.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"highlight-style":"../../../themes/code_block.css","output-file":"post-2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.43","theme":"../../../themes/theme.scss","title":"A Follow Up on my Hottest 100 Predictions","author":"Alfie Chadwick","date":"2024-02-03","lastmod":"`r Sys.Date()`","tags":["Music","ML"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}